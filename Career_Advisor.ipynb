{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4lsYDejSyjK10Cifo+PC9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matinapap/Career-Advisor-Chatbot/blob/main/Career_Advisor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ¤– Career Advisor Pipeline â€” Google Colab + Gemini + LangGraph\n",
        "Detailed description for the accompanying notebook / script\n",
        "\n",
        "---\n",
        "\n",
        "## âœ¨ Overview\n",
        "This project implements a **complete career guidance system** running on **Google Colab**, leveraging:\n",
        "\n",
        "- **Gemini (google.generativeai)**\n",
        "- **LangGraph** and modular agents\n",
        "- **RAG using FAISS + HuggingFace embeddings**\n",
        "- **SerpAPI** for course search\n",
        "- **Gradio GUI**\n",
        "\n",
        "The system analyzes user profiles, recommends suitable roles, generates learning plans, provides resume feedback (powered by RAG), and conducts mock interviews.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§  Pipeline Agents / Nodes\n",
        "\n",
        "### ğŸ” Profile Analyzer\n",
        "- Processes the text-based user profile (optionally including a PDF resume).  \n",
        "- Uses the **Gemini** model to extract skills, experiences, and interests.  \n",
        "- Returns a **detailed narrative description**.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ’¼ Career Suggestion Agent\n",
        "- Produces at least **two recommended career roles**.  \n",
        "- Includes justification, required skills, and steps for progression.  \n",
        "- Supports **fallback parsing** in case of LLM JSON failures.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“ Learning Path Generator\n",
        "Provides a complete learning plan for a chosen role, including:\n",
        "- technologies  \n",
        "- modules  \n",
        "- duration  \n",
        "- recommended courses (Udemy / YouTube / Coursera)  \n",
        "- progression roadmap  \n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“„ Resume Advisor (RAG-Powered)\n",
        "- Uses a **FAISS vectorstore**  \n",
        "- Employs **all-MiniLM-L6-v2** embeddings  \n",
        "- Performs similarity search on a local **resume_tips.txt** file  \n",
        "- Produces targeted resume improvements by combining RAG context + LLM reasoning  \n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ—£ï¸ Mock Interview Agent\n",
        "- Generates **realistic mock interview questions**  \n",
        "- Provides model answers and improvement tips  \n",
        "- Adapts to the user profile & chosen role (with RAG support)\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ§­ Personalized Learning Agent\n",
        "An advanced agent that:\n",
        "- Extracts **skill gaps**  \n",
        "- Builds a **personalized learning plan** using `learning_style` & `career_goals`  \n",
        "- Generates skill keywords and queries **SerpAPI** for online courses  \n",
        "- Saves user preferences to a JSON file  \n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§© LangGraph Architecture\n",
        "\n",
        "The system consists of 3 separate LangGraph pipelines:\n",
        "\n",
        "### ğŸ”¹ Default Flow  \n",
        "Profile â†’ Role Suggestions â†’ Learning Path\n",
        "\n",
        "### ğŸ”¹ Personalized Flow  \n",
        "Profile â†’ Role Suggestions â†’ Personalized Learning (with skill gaps & preferences)\n",
        "\n",
        "### ğŸ”¹ Interview Flow  \n",
        "Profile â†’ Role Suggestions â†’ Resume Feedback (RAG) â†’ Mock Interview"
      ],
      "metadata": {
        "id": "tOQqwtvyUiaQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Google Drive Conection"
      ],
      "metadata": {
        "id": "j6HQsIcmWYpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  # Î£Ï…Î½Î´Î­ÎµÎ¹ Ï„Î¿ Google Drive Î¼Îµ Ï„Î¿ Ï€ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½ Ï„Î¿Ï… Google Colab Î³Î¹Î± Î½Î± Î±Ï€Î¿ÎºÏ„Î®ÏƒÎ¿Ï…Î¼Îµ Ï€ÏÏŒÏƒÎ²Î±ÏƒÎ· ÏƒÎµ Î±ÏÏ‡ÎµÎ¯Î± Î±Ï€ÏŒ Ï„Î¿Î½ Î»Î¿Î³Î±ÏÎ¹Î±ÏƒÎ¼ÏŒ Î¼Î±Ï‚\n",
        "#  from google.colab import drive\n",
        "#  drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "o0NMD0L3HdmW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dependecies Installation"
      ],
      "metadata": {
        "id": "cPp-FurYWZ3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall -y langchain langchain-core langchain-community langchain-openai langchain-text-splitters langgraph pydantic\n",
        "\n",
        "# !pip install \"pydantic>=2.0,<3.0\"\n",
        "\n",
        "# !pip install langchain langchain-community langchain-openai langchain-text-splitters langgraph\n",
        "\n",
        "# !pip install gradio PyPDF2 faiss-cpu sentence-transformers google-generativeai"
      ],
      "metadata": {
        "id": "oi6a_8I-Sug0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "ssNUb2g5WhZ8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMPVseRWGBVP"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "import os\n",
        "import traceback\n",
        "from typing import TypedDict, Optional, List, Dict\n",
        "from datetime import datetime\n",
        "import textwrap\n",
        "\n",
        "# === Third-party libs commonly used ===\n",
        "import gradio as gr\n",
        "import PyPDF2\n",
        "import requests\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# === LangChain ===\n",
        "from langchain.tools import tool\n",
        "from langchain_openai import ChatOpenAI # ChatOpenAI moved to langchain_openai in 0.2.x\n",
        "from langchain_core.messages import HumanMessage # HumanMessage moved to langchain_core.messages\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# Embeddings & FAISS RAG\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter # Moved to langchain_text_splitters\n",
        "from langchain_core.documents import Document # Moved to langchain_core.documents\n",
        "from langchain_community.vectorstores import FAISS # Moved to langchain_community.vectorstores\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings # Moved to langchain_community.embeddings\n",
        "\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "# === Global constants ===\n",
        "PREFS_FILE = \"user_personalization.json\"\n",
        "HISTORY_FILE = \"/content/drive/MyDrive/career_advisor_files/history.json\"\n",
        "RESUME_TIPS_PATH = \"/content/drive/MyDrive/career_advisor_files/resume_tips.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Api Keys Configuration"
      ],
      "metadata": {
        "id": "8FhL7iaSXbMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key=userdata.get(\"Gemini_Key\"))\n",
        "\n",
        "# print(\"Î”Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î± Î¼Î¿Î½Ï„Î­Î»Î±:\")\n",
        "# for m in genai.list_models():\n",
        "#     methods = getattr(m, \"supported_generation_methods\", [])\n",
        "#     if \"generateContent\" in methods:\n",
        "#         print(\"âœ…\", m.name)\n",
        "\n",
        "model = genai.GenerativeModel(\"gemini-flash-latest\")"
      ],
      "metadata": {
        "id": "Aqk5uB5GGHlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Î‘ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Î‘ÏÏ‡ÎµÎ¯Î¿Ï… Î ÏÎ¿Ï„Î¹Î¼Î®ÏƒÎµÏ‰Î½"
      ],
      "metadata": {
        "id": "ClD9DkJXXeEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Initialize preferences file if missing ===\n",
        "def init_preferences_file():\n",
        "    if not os.path.exists(PREFS_FILE):\n",
        "        prefs = {\n",
        "            \"learning_style\": \"visual\",\n",
        "            \"career_goals\": \"ÎÎ± ÎµÏÎ³Î¬Î¶Î¿Î¼Î±Î¹ ÎµÎ¾ Î±Ï€Î¿ÏƒÏ„Î¬ÏƒÎµÏ‰Ï‚ ÎºÎ±Î¹ Î½Î± Î­Ï‡Ï‰ ÎµÏ…Î­Î»Î¹ÎºÏ„Î¿ Ï‰ÏÎ¬ÏÎ¹Î¿.\"\n",
        "        }\n",
        "        with open(PREFS_FILE, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(prefs, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "def save_user_preferences(learning_style: str, career_goals: str):\n",
        "    with open(PREFS_FILE, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump({\"learning_style\": learning_style, \"career_goals\": career_goals}, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "def load_personalization_preferences():\n",
        "    if not os.path.exists(PREFS_FILE):\n",
        "        init_preferences_file()\n",
        "    with open(PREFS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "        prefs = json.load(f)\n",
        "    return prefs.get(\"learning_style\", \"visual\"), prefs.get(\"career_goals\", \"\")"
      ],
      "metadata": {
        "id": "OwcTSEXhGQ2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Î’Î¬ÏƒÎ· Î“Î½ÏÏƒÎ·Ï‚ Î³Î¹Î± Î’Î¹Î¿Î³ÏÎ±Ï†Î¹ÎºÎ¬"
      ],
      "metadata": {
        "id": "bSAU5p6UYC3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Load resume tips for RAG ===\n",
        "if os.path.exists(RESUME_TIPS_PATH):\n",
        "    try:\n",
        "        with open(RESUME_TIPS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "            resume_tips = f.read()\n",
        "    except Exception:\n",
        "        resume_tips = \"\"\n",
        "else:\n",
        "    resume_tips = \"\"\n",
        "\n",
        "# Build small FAISS store from resume tips\n",
        "if resume_tips:\n",
        "    docs = [Document(page_content=resume_tips)]\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "    chunks = splitter.split_documents(docs)\n",
        "    embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    try:\n",
        "        db = FAISS.from_documents(chunks, embedding)\n",
        "    except Exception:\n",
        "        db = None\n",
        "else:\n",
        "    db = None"
      ],
      "metadata": {
        "id": "O7GeaFQOGUKz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helpers"
      ],
      "metadata": {
        "id": "2n9SvBywYWL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gemini_prompt(prompt: str, safety_fallback=\"(Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î±Ï€Î¬Î½Ï„Î·ÏƒÎ·)\"):\n",
        "    try:\n",
        "        return model.generate_content(prompt).text\n",
        "    except Exception as e:\n",
        "        return f\"{safety_fallback}\\n\\n(Î£Ï†Î¬Î»Î¼Î±: {e})\""
      ],
      "metadata": {
        "id": "phj2CA5Sn2lw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(pdf_path: str) -> str:\n",
        "    \"\"\"Î•Î¾Î¬Î³ÎµÎ¹ text Î±Ï€ÏŒ PDF (PyPDF2 fallback).\"\"\"\n",
        "    text = \"\"\n",
        "    try:\n",
        "        with open(pdf_path, \"rb\") as f:\n",
        "            reader = PyPDF2.PdfReader(f)\n",
        "            for page in reader.pages:\n",
        "                text += page.extract_text() or \"\"\n",
        "    except Exception as e:\n",
        "        text = f\"(Î£Ï†Î¬Î»Î¼Î± ÏƒÏ„Î·Î½ Î±Î½Î¬Î³Î½Ï‰ÏƒÎ· PDF: {e})\"\n",
        "    return text"
      ],
      "metadata": {
        "id": "H1uKOt39GYES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_output(raw_text: str) -> str:\n",
        "    if not raw_text:\n",
        "        return \"(No output)\"\n",
        "    raw_text = str(raw_text)\n",
        "    if raw_text.strip().startswith(\"<!DOCTYPE\") or raw_text.strip().startswith(\"<html\"):\n",
        "        import re\n",
        "        return re.sub(r\"<[^>]*>\", \"\", raw_text)\n",
        "    return raw_text"
      ],
      "metadata": {
        "id": "1zcfEuvcYkrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ LLM Wrapper ============\n",
        "\n",
        "def llm_run(prompt: str) -> str:\n",
        "    \"\"\"Unified LLM call for Gemini / LangChain.\"\"\"\n",
        "    try:\n",
        "        if hasattr(model, \"generate_content\"):\n",
        "            return model.generate_content(prompt).text\n",
        "        if hasattr(model, \"predict\"):\n",
        "            return model.predict(prompt)\n",
        "        if hasattr(model, \"generate\"):\n",
        "            messages = [HumanMessage(content=prompt)]\n",
        "            return model.generate(messages).generations[0][0].text\n",
        "        return \"(model Î´ÎµÎ½ Ï…Ï€Î¿ÏƒÏ„Î·ÏÎ¯Î¶ÎµÏ„Î±Î¹)\"\n",
        "    except Exception as e:\n",
        "        return f\"(model error: {e})\""
      ],
      "metadata": {
        "id": "y5PXr2GDGbYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tools"
      ],
      "metadata": {
        "id": "XDSQwna9Yazr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ Tools (LangChain-style) ============\n",
        "\n",
        "@tool\n",
        "def search_courses(skill: str, max_results: int = 3) -> str:\n",
        "    \"\"\"\n",
        "    Î‘Î½Î±Î¶Î·Ï„Î¬ online courses Î³Î¹Î± Î­Î½Î± skill (Udemy, Coursera, YouTube) Î¼Î­ÏƒÏ‰ SerpAPI.\n",
        "    Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ markdown list.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        api_key = None\n",
        "        if userdata:\n",
        "            api_key = userdata.get(\"SERPAPI_KEY\")\n",
        "        if not api_key:\n",
        "            api_key = os.environ.get(\"SERPAPI_KEY\")\n",
        "\n",
        "        if not api_key:\n",
        "            return \"ERROR: Missing SerpAPI key.\"\n",
        "        platforms = [\"udemy.com\", \"coursera.org\", \"youtube.com\"]\n",
        "        results_out = []\n",
        "\n",
        "        for site in platforms:\n",
        "            query = requests.utils.requote_uri(f\"{skill} course site:{site}\")\n",
        "            url = f\"https://serpapi.com/search.json?q={query}&api_key={api_key}&num={max_results}\"\n",
        "            try:\n",
        "                r = requests.get(url, timeout=8)\n",
        "                if r.status_code != 200:\n",
        "                    continue\n",
        "                data = r.json().get(\"organic_results\", [])\n",
        "                for item in data[:max_results]:\n",
        "                    title = item.get(\"title\")\n",
        "                    link = item.get(\"link\")\n",
        "                    if title and link:\n",
        "                        results_out.append(f\"- [{title}]({link})\")\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "        return \"\\n\".join(results_out) if results_out else f\"(Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ courses Î³Î¹Î± Ï„Î¿ skill: {skill})\"\n",
        "    except Exception as e:\n",
        "        return f\"(search_courses error: {e})\"\n"
      ],
      "metadata": {
        "id": "OwgPbumwYZOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agent Initialization"
      ],
      "metadata": {
        "id": "LWAhUdELYfnx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agents"
      ],
      "metadata": {
        "id": "xujToZ4kYpCO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Profile Analyzer"
      ],
      "metadata": {
        "id": "R9c95H5-k9Yu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_profile(user_profile: str) -> str:\n",
        "    prompt = f\"\"\"\n",
        "Î‘Î½Î¬Î»Ï…ÏƒÎµ Ï„Î¿ Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰ Ï€ÏÎ¿Ï†Î¯Î» Ï‡ÏÎ®ÏƒÏ„Î· ÎºÎ±Î¹ Î³ÏÎ¬ÏˆÎµ Î­Î½Î± Î±Î½Î±Î»Ï…Ï„Î¹ÎºÏŒ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ ÏƒÏ„Î± ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬\n",
        "Ï€Î¿Ï… Ï€ÎµÏÎ¹Î³ÏÎ¬Ï†ÎµÎ¹ Ï„Î¹Ï‚ Î´ÎµÎ¾Î¹ÏŒÏ„Î·Ï„ÎµÏ‚, Î³Î½ÏÏƒÎµÎ¹Ï‚ ÎºÎ±Î¹ ÎµÎ½Î´Î¹Î±Ï†Î­ÏÎ¿Î½Ï„Î± Ï„Î¿Ï… Ï‡ÏÎ®ÏƒÏ„Î·.\n",
        "Î ÎµÏÎ¹Î­Î³ÏÎ±ÏˆÎµ Î±Î½Î±Î»Ï…Ï„Î¹ÎºÎ¬ ÎºÎ±Î¹ Ï‡Ï‰ÏÎ¯Ï‚ Î»Î¯ÏƒÏ„ÎµÏ‚.\n",
        "\n",
        "Î ÏÎ¿Ï†Î¯Î»:\n",
        "{user_profile}\n",
        "\"\"\"\n",
        "    return gemini_prompt(prompt)"
      ],
      "metadata": {
        "id": "LeAQTESolASA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Career Suggestions"
      ],
      "metadata": {
        "id": "Xsie6k9blE9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def suggest_careers(skills_summary: str) -> str:\n",
        "    prompt = f\"\"\"\n",
        "ÎœÎµ Î²Î¬ÏƒÎ· Ï„Î¹Ï‚ Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰ Î´ÎµÎ¾Î¹ÏŒÏ„Î·Ï„ÎµÏ‚:\n",
        "\n",
        "{skills_summary}\n",
        "\n",
        "Î“ÏÎ¬ÏˆÎµ Î±Î½Î±Î»Ï…Ï„Î¹ÎºÎ¬, ÏƒÎµ ÏƒÏ…Î½ÎµÎºÏ„Î¹ÎºÏŒ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ ÏƒÏ„Î± ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬:\n",
        "- 2 ÎºÎ±Ï„Î¬Î»Î»Î·Î»Î¿Ï…Ï‚ ÎµÏ€Î±Î³Î³ÎµÎ»Î¼Î±Ï„Î¹ÎºÎ¿ÏÏ‚ ÏÏŒÎ»Î¿Ï…Ï‚\n",
        "- Î“Î¹Î±Ï„Î¯ Ï„Î±Î¹ÏÎ¹Î¬Î¶Î¿Ï…Î½\n",
        "- Î‘Ï€Î±ÏÎ±Î¯Ï„Î·Ï„ÎµÏ‚ Î´ÎµÎ¾Î¹ÏŒÏ„Î·Ï„ÎµÏ‚\n",
        "- Î¤Î¹ Î¸Î± Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± ÎºÎ¬Î½ÎµÎ¹ Î¿ Ï‡ÏÎ®ÏƒÏ„Î·Ï‚ Î³Î¹Î± Î½Î± Ï€ÏÎ¿Ï‡Ï‰ÏÎ®ÏƒÎµÎ¹\n",
        "\"\"\"\n",
        "    return gemini_prompt(prompt)"
      ],
      "metadata": {
        "id": "gp_RrEv3lHPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Suggest Learning Path"
      ],
      "metadata": {
        "id": "Kk3mPaBUlMb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def suggest_learning_path(role: str) -> str:\n",
        "    prompt = f\"\"\"\n",
        "Î ÏÏŒÏ„ÎµÎ¹Î½Îµ Î­Î½Î± Î±Î½Î±Î»Ï…Ï„Î¹ÎºÏŒ Ï€Î»Î¬Î½Î¿ ÎµÎºÎ¼Î¬Î¸Î·ÏƒÎ·Ï‚ Î³Î¹Î± Ï„Î¿Î½ ÏÏŒÎ»Î¿: {role}.\n",
        "Î£Ï…Î¼Ï€ÎµÏÎ¯Î»Î±Î²Îµ:\n",
        "- Î¤ÎµÏ‡Î½Î¿Î»Î¿Î³Î¯ÎµÏ‚ / Î­Î½Î½Î¿Î¹ÎµÏ‚ Ï€Î¿Ï… Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± Î¼Î¬Î¸ÎµÎ¹\n",
        "- Î ÏÎ¿Ï„ÎµÎ¹Î½ÏŒÎ¼ÎµÎ½Î± online Î¼Î±Î¸Î®Î¼Î±Ï„Î± (Coursera, YouTube)\n",
        "- Î•ÎºÏ„Î¹Î¼ÏÎ¼ÎµÎ½Î¿Ï‚ Ï‡ÏÏŒÎ½Î¿Ï‚ Î³Î¹Î± ÎºÎ¬Î¸Îµ Î¸Î­Î¼Î±\n",
        "Î“ÏÎ¬ÏˆÎµ ÏƒÎµ ÎµÎ»Î»Î·Î½Î¹ÎºÏŒ ÏƒÏ…Î½ÎµÎºÏ„Î¹ÎºÏŒ ÎºÎµÎ¯Î¼ÎµÎ½Î¿, Ï‡Ï‰ÏÎ¯Ï‚ bullets.\n",
        "\"\"\"\n",
        "    return gemini_prompt(prompt)"
      ],
      "metadata": {
        "id": "ngpxM48wlS_i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Suggest Resume Improvements"
      ],
      "metadata": {
        "id": "sxGiI_PvlW0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def suggest_resume_improvements(resume_text: str) -> str:\n",
        "    \"\"\"\n",
        "    Î‘Î¾Î¹Î¿Î»Î¿Î³ÎµÎ¯ Ï„Î¿ Î²Î¹Î¿Î³ÏÎ±Ï†Î¹ÎºÏŒ, ÎºÎ¬Î½ÎµÎ¹ RAG Î¼Îµ db Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ ÎºÎ±Î¹ ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹\n",
        "    Î±Î½Î±Î»Ï…Ï„Î¹ÎºÎ¬ ÏƒÏ‡ÏŒÎ»Î¹Î± ÎºÎ±Î¹ Ï€ÏÎ¿Ï„Î¬ÏƒÎµÎ¹Ï‚ Î²ÎµÎ»Ï„Î¯Ï‰ÏƒÎ·Ï‚ ÏƒÏ„Î± ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬, ÏƒÎµ Ï€Î»Î®ÏÎµÏ‚ ÎºÎµÎ¯Î¼ÎµÎ½Î¿.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        context = \"\"\n",
        "        if db:\n",
        "            try:\n",
        "                relevant = db.similarity_search(resume_text, k=3)\n",
        "                context = \"\\n\\n\".join([d.page_content for d in relevant])\n",
        "            except Exception:\n",
        "                context = \"\"\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎµ Ï„Î¿ Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰ Î²Î¹Î¿Î³ÏÎ±Ï†Î¹ÎºÏŒ ÎºÎ±Î¹ Î´ÏÏƒÎµ **Î±Î½Î±Î»Ï…Ï„Î¹ÎºÎ¬ ÏƒÏ‡ÏŒÎ»Î¹Î±** ÏƒÏ„Î± ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬.\n",
        "Î£Ï…Î¼Ï€ÎµÏÎ¹Î­Î»Î±Î²Îµ:\n",
        "- Î¤Î¹ Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³ÎµÎ¯ ÎºÎ±Î»Î¬ ÎºÎ±Î¹ Ï„Î¹ ÏŒÏ‡Î¹\n",
        "- Î ÏÎ¿Ï„Î¬ÏƒÎµÎ¹Ï‚ Î²ÎµÎ»Ï„Î¯Ï‰ÏƒÎ·Ï‚ Î³Î¹Î± ÎºÎ¬Î¸Îµ ÎµÎ½ÏŒÏ„Î·Ï„Î± (Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·, Î•ÏÎ³Î±ÏƒÎ¹Î±ÎºÎ® ÎµÎ¼Ï€ÎµÎ¹ÏÎ¯Î±, Î”ÎµÎ¾Î¹ÏŒÏ„Î·Ï„ÎµÏ‚)\n",
        "- Î£Ï…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Ï€Î¿Ï… Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Ï€ÏÎ¿ÏƒÏ„ÎµÎ¸ÎµÎ¯ Î® Î±Î½Ï„Î¹ÎºÎ±Ï„Î±ÏƒÏ„Î±Î¸ÎµÎ¯\n",
        "\n",
        "Î’Î¹Î¿Î³ÏÎ±Ï†Î¹ÎºÏŒ:\n",
        "{resume_text}\n",
        "\n",
        "ÎŸÎ´Î·Î³Î¯ÎµÏ‚ / Î£Ï…Î¼Ï€Î»Î·ÏÏ‰Î¼Î±Ï„Î¹ÎºÏŒ context:\n",
        "{context}\n",
        "\"\"\"\n",
        "        raw = llm_run(prompt)\n",
        "\n",
        "        return clean_output(raw)\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"(Î£Ï†Î¬Î»Î¼Î± suggest_resume_improvements: {e})\"\n"
      ],
      "metadata": {
        "id": "h5kA_x5xlcuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Interview Agent"
      ],
      "metadata": {
        "id": "3YOlWXONlfYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def interview_agent(user_profile: str, chosen_role: str, chat_context: str = \"\", resume_text: Optional[str] = None) -> str:\n",
        "    \"\"\"\n",
        "    Î•Ï„Î¿Î¹Î¼Î¬Î¶ÎµÎ¹ mock ÏƒÏ…Î½Î­Î½Ï„ÎµÏ…Î¾Î· Î¼Îµ Ï€Î»Î®ÏÎµÎ¹Ï‚ ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚ ÎºÎ±Î¹ Î±Î½Î±Î»Ï…Ï„Î¹ÎºÎ­Ï‚ ÎµÎ½Î´ÎµÎ¹ÎºÏ„Î¹ÎºÎ­Ï‚ Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚.\n",
        "    Î— Î­Î¾Î¿Î´Î¿Ï‚ ÎµÎ¯Î½Î±Î¹ human-readable ÎºÎµÎ¯Î¼ÎµÎ½Î¿, ÏŒÏ‡Î¹ Î±Ï€Î»ÏÏ‚ Î»Î¯ÏƒÏ„ÎµÏ‚.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        skills_summary = analyze_profile(user_profile + \"\\n\\n\" + chat_context)\n",
        "        rag_context = \"\"\n",
        "        if resume_text and db:\n",
        "            try:\n",
        "                relevant = db.similarity_search(resume_text, k=3)\n",
        "                rag_context = \"\\n\\n\".join([d.page_content for d in relevant])\n",
        "            except Exception:\n",
        "                rag_context = \"\"\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "Î”Î·Î¼Î¹Î¿ÏÏÎ³Î·ÏƒÎµ Î¼Î¹Î± mock ÏƒÏ…Î½Î­Î½Ï„ÎµÏ…Î¾Î· Î³Î¹Î± Ï„Î¿Î½ Ï‡ÏÎ®ÏƒÏ„Î· Î¼Îµ Î²Î¬ÏƒÎ· Ï„Î± Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰ ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î±.\n",
        "Î£Ï…Î¼Ï€ÎµÏÎ¹Î­Î»Î±Î²Îµ **Î±Î½Î±Î»Ï…Ï„Î¹ÎºÎ­Ï‚ Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚**, ÎµÏ€ÎµÎ¾Î·Î³Î®ÏƒÎµÎ¹Ï‚ ÎºÎ±Î¹ tips Î³Î¹Î± ÎºÎ¬Î¸Îµ ÎµÏÏÏ„Î·ÏƒÎ·.\n",
        "\n",
        "Î ÏÎ¿Ï†Î¯Î»:\n",
        "{user_profile}\n",
        "\n",
        "Î¡ÏŒÎ»Î¿Ï‚:\n",
        "{chosen_role}\n",
        "\n",
        "Î”ÎµÎ¾Î¹ÏŒÏ„Î·Ï„ÎµÏ‚:\n",
        "{skills_summary}\n",
        "\n",
        "Î’Î¹Î¿Î³ÏÎ±Ï†Î¹ÎºÏŒ / context:\n",
        "{rag_context}\n",
        "\n",
        "ÎœÎ¿ÏÏ†Î®:\n",
        "1. Î•ÏÏÏ„Î·ÏƒÎ·: ...\n",
        "   Î‘Ï€Î¬Î½Ï„Î·ÏƒÎ·: ...\n",
        "   (Î ÏÏŒÏƒÎ¸ÎµÏ„ÎµÏ‚ ÏƒÏ…Î¼Î²Î¿Ï…Î»Î­Ï‚ Î® ÎµÎ¾Î·Î³Î®ÏƒÎµÎ¹Ï‚)\n",
        "\"\"\"\n",
        "        raw = llm_run(prompt)\n",
        "        return clean_output(raw)\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"(Î£Ï†Î¬Î»Î¼Î± interview_agent: {e})\""
      ],
      "metadata": {
        "id": "iFeJEcoLlnJE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Personalized Learning"
      ],
      "metadata": {
        "id": "9bN7I9tLlqBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def personalized_learning(user_skills_text, target_role, personalization_info):\n",
        "    try:\n",
        "        prompt_role_desc = f\"\"\"\n",
        "Î”ÏÏƒÎµ Ï€ÎµÏÎ¹Î³ÏÎ±Ï†Î® Î³Î¹Î± Ï„Î¿Î½ ÏÏŒÎ»Î¿: {target_role}\n",
        "Î ÎµÏÎ¹Î­Î³ÏÎ±ÏˆÎµ:\n",
        "- Î¤Î¹ ÎºÎ±Î¸Î®ÎºÎ¿Î½Ï„Î± Î­Ï‡ÎµÎ¹\n",
        "- Î Î¿Î¹ÎµÏ‚ Ï„ÎµÏ‡Î½Î¿Î»Î¿Î³Î¯ÎµÏ‚ / Î´ÎµÎ¾Î¹ÏŒÏ„Î·Ï„ÎµÏ‚ Î±Ï€Î±Î¹Ï„Î¿ÏÎ½Ï„Î±Î¹\n",
        "\"\"\"\n",
        "        role_description = gemini_prompt(prompt_role_desc)\n",
        "\n",
        "        prompt_gap = f\"\"\"\n",
        "Î£ÏÎ³ÎºÏÎ¹Î½Îµ Ï„Î¹Ï‚ Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰ Î´ÎµÎ¾Î¹ÏŒÏ„Î·Ï„ÎµÏ‚ Ï„Î¿Ï… Ï‡ÏÎ®ÏƒÏ„Î· Î¼Îµ Ï„Î¹Ï‚ Î±Ï€Î±Î¹Ï„Î®ÏƒÎµÎ¹Ï‚ Ï„Î¿Ï… ÏÏŒÎ»Î¿Ï…:\n",
        "\n",
        "--- Î”ÎµÎ¾Î¹ÏŒÏ„Î·Ï„ÎµÏ‚ Î§ÏÎ®ÏƒÏ„Î· ---\n",
        "{user_skills_text}\n",
        "\n",
        "--- Î ÎµÏÎ¹Î³ÏÎ±Ï†Î® Î¡ÏŒÎ»Î¿Ï… ---\n",
        "{role_description}\n",
        "\n",
        "Î’ÏÎµÏ‚:\n",
        "- Î Î¿Î¹ÎµÏ‚ Î´ÎµÎ¾Î¹ÏŒÏ„Î·Ï„ÎµÏ‚ Î»ÎµÎ¯Ï€Î¿Ï…Î½;\n",
        "- Î£Îµ Ï€Î¿Î¹ÎµÏ‚ ÎµÎ¯Î½Î±Î¹ Î±ÏÏ‡Î¬ÏÎ¹Î¿Ï‚;\n",
        "- Î Î¿Î¹Î± ÎµÎ¯Î½Î±Î¹ Ï„Î± ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÏŒÏ„ÎµÏÎ± gaps Î³Î¹Î± Î½Î± ÎºÎ±Î»ÏÏˆÎµÎ¹;\n",
        "Î”ÏÏƒÎµ Ï‰Ï‚ Î»Î¯ÏƒÏ„Î±.\n",
        "\"\"\"\n",
        "        skill_gaps = gemini_prompt(prompt_gap)\n",
        "\n",
        "        prompt_learning = f\"\"\"\n",
        "ÎŸ Ï‡ÏÎ®ÏƒÏ„Î·Ï‚ Î¸Î­Î»ÎµÎ¹ Î½Î± Î³Î¯Î½ÎµÎ¹: {target_role}\n",
        "Î”Î¯Î½ÎµÎ¹ Î­Î¼Ï†Î±ÏƒÎ· ÏƒÎµ:\n",
        "- Learning style: {personalization_info.get('learning_style','-')}\n",
        "- Career goals: {personalization_info.get('career_goals','-')}\n",
        "\n",
        "Î’Î¿Î®Î¸Î·ÏƒÎ­ Ï„Î¿Î½ Î½Î± Î¼Î¬Î¸ÎµÎ¹ ÏŒ,Ï„Î¹ Ï„Î¿Ï… Î»ÎµÎ¯Ï€ÎµÎ¹: {skill_gaps}\n",
        "\n",
        "Î¦Ï„Î¹Î¬Î¾Îµ Î­Î½Î± Ï€Î»Î¬Î½Î¿ ÎµÎºÎ¼Î¬Î¸Î·ÏƒÎ·Ï‚ (Î¸ÎµÎ¼Î±Ï„Î¹ÎºÏŒ), ÎºÎ±Î¹ Î´ÏÏƒÎµ:\n",
        "- Î¤ÎµÏ‡Î½Î¿Î»Î¿Î³Î¯ÎµÏ‚ Î® Î­Î½Î½Î¿Î¹ÎµÏ‚ Ï€ÏÎ¿Ï‚ ÎµÎºÎ¼Î¬Î¸Î·ÏƒÎ·\n",
        "- Î ÏÎ¿Ï„Î¬ÏƒÎµÎ¹Ï‚ Î¼Î±Î¸Î·Î¼Î¬Ï„Ï‰Î½ Î±Ï€ÏŒ Coursera, YouTube\n",
        "- Î ÏÎ¿Ï„ÎµÎ¹Î½ÏŒÎ¼ÎµÎ½Î¿ Ï‡ÏÏŒÎ½Î¿Ï‚ Î±Î½Î¬ Î¸Î­Î¼Î±\n",
        "\"\"\"\n",
        "        learning_plan = gemini_prompt(prompt_learning)\n",
        "\n",
        "        prompt_skills = f\"\"\"\n",
        "Î•Î¯ÏƒÎ±Î¹ Î²Î¿Î·Î¸ÏŒÏ‚ Î³Î¹Î± Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ· Î¼Î±Î¸Î·Î¼Î¬Ï„Ï‰Î½.\n",
        "Î‘Ï€ÏŒ Ï„Î·Î½ Î±Î½Î¬Î»Ï…ÏƒÎ· Î´ÎµÎ¾Î¹Î¿Ï„Î®Ï„Ï‰Î½ ÎµÎ¾Î¬Î³ÎµÎ¹Ï‚ Î­Ï‰Ï‚ 4 ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÎ­Ï‚ Î´ÎµÎ¾Î¹ÏŒÏ„Î·Ï„ÎµÏ‚.\n",
        "ÎœÎµÏ„Î­Ï„ÏÎµÏˆÎµ Ï„Î¹Ï‚ ÏƒÎµ ÏƒÏÎ½Ï„Î¿Î¼Î± Î±Î³Î³Î»Î¹ÎºÎ¬ keywords.\n",
        "Î‘Ï€Î¬Î½Ï„Î·ÏƒÎµ ÏƒÎµ JSON, Ï€Ï‡:\n",
        "{{\n",
        "  \"skills\": [\"python\", \"sql\"]\n",
        "}}\n",
        "\n",
        "Skill gaps:\n",
        "{skill_gaps}\n",
        "\n",
        "Î¡ÏŒÎ»Î¿Ï‚:\n",
        "{target_role}\n",
        "\"\"\"\n",
        "        raw_skills = gemini_prompt(prompt_skills)\n",
        "        import json, re\n",
        "        cleaned = re.sub(r'```json|```', '', raw_skills).strip()\n",
        "        try:\n",
        "            agent_output = json.loads(cleaned)\n",
        "            skills = agent_output.get(\"skills\", [])\n",
        "        except Exception:\n",
        "            skills = []\n",
        "        if not skills:\n",
        "            skills = [\"python\", \"sql\", \"data analysis\", \"excel\"]\n",
        "\n",
        "        courses_output = \"\"\n",
        "        for skill in skills:\n",
        "            try:\n",
        "                results = search_courses.invoke({\"skill\": skill, \"max_results\": 3})\n",
        "            except Exception:\n",
        "                results = \"(Î£Ï†Î¬Î»Î¼Î± ÏƒÏ„Î·Î½ Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ· Î¼Î±Î¸Î·Î¼Î¬Ï„Ï‰Î½)\"\n",
        "            courses_output += f\"### {skill}\\n{results}\\n\\n\"\n",
        "\n",
        "\n",
        "        return f\"\"\"\n",
        "## ğŸ¯ Î¡ÏŒÎ»Î¿Ï‚: {target_role}\n",
        "\n",
        "## ğŸ” Î‘Î½Î¬Î»Ï…ÏƒÎ· Skill Gaps\n",
        "{skill_gaps}\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“ Î ÏÎ¿ÏƒÏ‰Ï€Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î¿ Î Î»Î¬Î½Î¿ Î•ÎºÎ¼Î¬Î¸Î·ÏƒÎ·Ï‚\n",
        "{learning_plan}\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“ Î ÏÎ¿Ï„ÎµÎ¹Î½ÏŒÎ¼ÎµÎ½Î± ÎœÎ±Î¸Î®Î¼Î±Ï„Î±\n",
        "{courses_output}\n",
        "\"\"\"\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        return f\"(Error in personalized_learning_with_courses: {e})\\n{traceback.format_exc()}\""
      ],
      "metadata": {
        "id": "GhNLJStoGr8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LangGraph Agent Flow"
      ],
      "metadata": {
        "id": "s7Fr-EW0YuWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === LangGraph Agent Flow ===\n",
        "class AgentState(TypedDict):\n",
        "    profile: str\n",
        "    resume_text: str\n",
        "    role: str\n",
        "    skills: str\n",
        "    suggested_roles: str\n",
        "    learning_plan: str\n",
        "    resume_feedback: str\n",
        "    interview_questions: str\n",
        "    learning_style: str\n",
        "    career_goals: str\n",
        "\n",
        "def node_wrapper(output_key, func, *input_keys):\n",
        "    \"\"\"\n",
        "    Î“ÎµÎ½Î¹ÎºÏŒÏ‚ decorator Î³Î¹Î± ÎºÏŒÎ¼Î²Î¿Ï…Ï‚ LangGraph.\n",
        "    ÎšÎ±Î»ÎµÎ¯ Ï„Î· function Î¼Îµ Ï„Î± input keys Î±Ï€ÏŒ Ï„Î¿ state ÎºÎ±Î¹ ÎµÎ½Î·Î¼ÎµÏÏÎ½ÎµÎ¹ Ï„Î¿ output_key.\n",
        "    \"\"\"\n",
        "    def wrapper(state: AgentState):\n",
        "        try:\n",
        "            inputs = [state.get(k, \"\") for k in input_keys]\n",
        "            state[output_key] = func(*inputs)\n",
        "        except Exception as e:\n",
        "            state[output_key] = f\"(Î£Ï†Î¬Î»Î¼Î± ÏƒÏ„Î¿ {output_key}: {e})\"\n",
        "        return state\n",
        "    return wrapper\n",
        "\n",
        "\n",
        "# === Agents ===\n",
        "\n",
        "analyze_profile_node = node_wrapper(\"skills\", analyze_profile, \"profile\")\n",
        "\n",
        "def suggest_roles_node(state: AgentState):\n",
        "    try:\n",
        "        output = suggest_careers(state.get(\"skills\", \"\"))\n",
        "        output_clean = clean_output(output)\n",
        "\n",
        "        try:\n",
        "            roles = json.loads(output_clean)\n",
        "            state[\"suggested_roles\"] = roles\n",
        "            if not state.get(\"role\") and roles:\n",
        "                state[\"role\"] = roles[0].get(\"title\", \"No role\")\n",
        "        except json.JSONDecodeError:\n",
        "            state[\"suggested_roles\"] = output_clean\n",
        "            if not state.get(\"role\"):\n",
        "                first_role = re.search(r\"1\\.\\s+(.*?)\\n\", output_clean)\n",
        "                state[\"role\"] = first_role.group(1).strip() if first_role else \"No role\"\n",
        "\n",
        "    except Exception as e:\n",
        "        state[\"suggested_roles\"] = f\"(Î£Ï†Î¬Î»Î¼Î± ÏƒÏ„Î¿ suggest_roles_node: {e})\"\n",
        "        if not state.get(\"role\"):\n",
        "            state[\"role\"] = \"No role\"\n",
        "    return state\n",
        "\n",
        "\n",
        "learning_path_node = node_wrapper(\"learning_plan\", suggest_learning_path, \"role\")\n",
        "\n",
        "personalized_learning_node = node_wrapper(\n",
        "    \"learning_plan\",\n",
        "    lambda skills, role, learning_style, career_goals: personalized_learning(\n",
        "        skills,\n",
        "        role,\n",
        "        {\n",
        "            \"learning_style\": learning_style,\n",
        "            \"career_goals\": career_goals\n",
        "        }\n",
        "    ),\n",
        "    \"skills\", \"role\", \"learning_style\", \"career_goals\"\n",
        ")\n",
        "\n",
        "\n",
        "def resume_feedback_node(state: AgentState):\n",
        "    try:\n",
        "        if state.get(\"resume_text\"):\n",
        "            feedback = suggest_resume_improvements(state[\"resume_text\"])\n",
        "            state[\"resume_feedback\"] = clean_output(feedback)\n",
        "        else:\n",
        "            state[\"resume_feedback\"] = \"(Î”ÎµÎ½ Ï…Ï€Î¿Î²Î»Î®Î¸Î·ÎºÎµ Î²Î¹Î¿Î³ÏÎ±Ï†Î¹ÎºÏŒ)\"\n",
        "    except Exception as e:\n",
        "        state[\"resume_feedback\"] = f\"(Î£Ï†Î¬Î»Î¼Î± resume_feedback_node: {e})\"\n",
        "    return state\n",
        "\n",
        "interview_node = node_wrapper(\n",
        "    \"interview_questions\",\n",
        "    lambda profile, role, resume_text: clean_output(\n",
        "        interview_agent(profile, role, chat_context=\"\", resume_text=resume_text or profile)\n",
        "    ),\n",
        "    \"profile\", \"role\", \"resume_text\"\n",
        ")\n",
        "\n",
        "\n",
        "# === Graphs ===\n",
        "\n",
        "# Default Flow\n",
        "builder_default = StateGraph(AgentState)\n",
        "builder_default.add_node(\"AnalyzeProfile\", analyze_profile_node)\n",
        "builder_default.add_node(\"SuggestRoles\", suggest_roles_node)\n",
        "builder_default.add_node(\"LearningPath\", learning_path_node)\n",
        "builder_default.add_edge(\"AnalyzeProfile\", \"SuggestRoles\")\n",
        "builder_default.add_edge(\"SuggestRoles\", \"LearningPath\")\n",
        "builder_default.add_edge(\"LearningPath\", END)\n",
        "builder_default.set_entry_point(\"AnalyzeProfile\")\n",
        "default_graph = builder_default.compile()\n",
        "\n",
        "# Personalized Flow\n",
        "builder_personalized = StateGraph(AgentState)\n",
        "builder_personalized.add_node(\"AnalyzeProfile\", analyze_profile_node)\n",
        "builder_personalized.add_node(\"SuggestRoles\", suggest_roles_node)\n",
        "builder_personalized.add_node(\"PersonalizedLearning\", personalized_learning_node)\n",
        "builder_personalized.add_edge(\"AnalyzeProfile\", \"SuggestRoles\")\n",
        "builder_personalized.add_edge(\"SuggestRoles\", \"PersonalizedLearning\")\n",
        "builder_personalized.add_edge(\"PersonalizedLearning\", END)\n",
        "builder_personalized.set_entry_point(\"AnalyzeProfile\")\n",
        "personalized_graph = builder_personalized.compile()\n",
        "\n",
        "# Interview Flow\n",
        "builder_interview = StateGraph(AgentState)\n",
        "builder_interview.add_node(\"AnalyzeProfile\", analyze_profile_node)\n",
        "builder_interview.add_node(\"SuggestRoles\", suggest_roles_node)\n",
        "builder_interview.add_node(\"ResumeFeedback\", resume_feedback_node)\n",
        "builder_interview.add_node(\"Interview\", interview_node)\n",
        "builder_interview.add_edge(\"AnalyzeProfile\", \"SuggestRoles\")\n",
        "builder_interview.add_edge(\"SuggestRoles\", \"ResumeFeedback\")\n",
        "builder_interview.add_edge(\"ResumeFeedback\", \"Interview\")\n",
        "builder_interview.add_edge(\"Interview\", END)\n",
        "builder_interview.set_entry_point(\"AnalyzeProfile\")\n",
        "interview_graph = builder_interview.compile()\n"
      ],
      "metadata": {
        "id": "Vhmq0Ft0GvBk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pipeline"
      ],
      "metadata": {
        "id": "eQ4_-l_DYxWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ Orchestrator: full_pipeline (like original but agentic) ============\n",
        "\n",
        "def full_pipeline(\n",
        "    user_profile: str,\n",
        "    chosen_role: str = \"\",\n",
        "    resume_file=None,\n",
        "    chat_history_messages: Optional[list] = None,\n",
        "    mode = \"default\",\n",
        "    learning_style: Optional[str] = None,\n",
        "    career_goals: Optional[str] = None,\n",
        "    personalized: bool = False\n",
        "):\n",
        "    # Load personalization defaults if needed\n",
        "    ls, cg = load_personalization_preferences()\n",
        "    learning_style = learning_style or ls\n",
        "    career_goals = career_goals or cg\n",
        "\n",
        "    # === Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î’Î¹Î¿Î³ÏÎ±Ï†Î¹ÎºÎ¿Ï (PDF) ===\n",
        "    resume_text = \"\"\n",
        "    resume_clean = \"\"\n",
        "    if resume_file:\n",
        "        try:\n",
        "            resume_text = extract_text_from_pdf(resume_file.name)\n",
        "            resume_clean = clean_output(resume_text)\n",
        "            user_profile += f\"\\n\\n{resume_clean}\"\n",
        "        except Exception as e:\n",
        "            resume_text = f\"(Î£Ï†Î¬Î»Î¼Î± PDF: {e})\"\n",
        "            resume_clean = resume_text\n",
        "\n",
        "    # initial state\n",
        "    initial_state: AgentState = AgentState(\n",
        "        profile=user_profile,\n",
        "        resume_text=resume_text,\n",
        "        role=chosen_role or \"\",\n",
        "        skills=\"\",\n",
        "        suggested_roles=\"\",\n",
        "        learning_plan=\"\",\n",
        "        resume_feedback=\"\",\n",
        "        interview_questions=\"\",\n",
        "        learning_style=learning_style,\n",
        "        career_goals=career_goals\n",
        "    )\n",
        "\n",
        "   # ============== Î•Ï€Î¹Î»Î¿Î³Î® Graph Î±Î½Î¬ mode ==============\n",
        "    if mode == \"default\":\n",
        "      final_state = default_graph.invoke(initial_state)\n",
        "\n",
        "      if chosen_role.strip():\n",
        "          result_markdown = f\"\"\"\n",
        "  ## ğŸ§  Î‘Î½Î¬Î»Ï…ÏƒÎ· Î”ÎµÎ¾Î¹Î¿Ï„Î®Ï„Ï‰Î½\n",
        "  {final_state['skills']}\n",
        "\n",
        "  ## ğŸ“ Î ÏÎ¿Ï„ÎµÎ¹Î½ÏŒÎ¼ÎµÎ½Î¿ Î Î»Î¬Î½Î¿ Î•ÎºÎ¼Î¬Î¸Î·ÏƒÎ·Ï‚\n",
        "  {final_state['learning_plan']}\n",
        "  \"\"\"\n",
        "      else:\n",
        "          result_markdown = f\"\"\"\n",
        "  ## ğŸ§  Î‘Î½Î¬Î»Ï…ÏƒÎ· Î”ÎµÎ¾Î¹Î¿Ï„Î®Ï„Ï‰Î½\n",
        "  {final_state['skills']}\n",
        "\n",
        "  ## ğŸ’¼ Î ÏÎ¿Ï„ÎµÎ¹Î½ÏŒÎ¼ÎµÎ½Î¿Î¹ Î¡ÏŒÎ»Î¿Î¹\n",
        "  {final_state['suggested_roles']}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    elif mode == \"personalized\":\n",
        "      final_state = personalized_graph.invoke(initial_state)\n",
        "      save_user_preferences(learning_style, career_goals)\n",
        "      result_markdown = final_state[\"learning_plan\"]\n",
        "    elif mode == \"interview\":\n",
        "      final_state = interview_graph.invoke(initial_state)\n",
        "      parts = []\n",
        "\n",
        "      # Resume feedback\n",
        "      resume_feedback = final_state.get(\"resume_feedback\") or \"(Î”ÎµÎ½ Ï…Ï€Î¿Î²Î»Î®Î¸Î·ÎºÎµ Î® ÏƒÏ†Î¬Î»Î¼Î± ÏƒÏ„Î¿ Î²Î¹Î¿Î³ÏÎ±Ï†Î¹ÎºÏŒ)\"\n",
        "      parts.append(f\"## âœï¸ Î£Ï‡ÏŒÎ»Î¹Î± Î³Î¹Î± Ï„Î¿ Î’Î¹Î¿Î³ÏÎ±Ï†Î¹ÎºÏŒ\\n{resume_feedback}\")\n",
        "\n",
        "      # Interview questions\n",
        "      interview_text = final_state.get(\"interview_questions\") or \"(Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚ ÏƒÏ…Î½Î­Î½Ï„ÎµÏ…Î¾Î·Ï‚)\"\n",
        "      parts.append(f\"## ğŸ¤ Mock Î£Ï…Î½Î­Î½Ï„ÎµÏ…Î¾Î·\\n{interview_text}\")\n",
        "\n",
        "      result_markdown = \"\\n\\n\".join(parts)\n",
        "    else:\n",
        "      result_markdown = \"âš ï¸ ÎœÎ· Ï…Ï€Î¿ÏƒÏ„Î·ÏÎ¹Î¶ÏŒÎ¼ÎµÎ½Î· Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¯Î±.\"\n",
        "      final_state = {}\n",
        "\n",
        "    print(result_markdown)\n",
        "\n",
        "    return result_markdown, final_state\n"
      ],
      "metadata": {
        "id": "_O3F_Q6eGwuE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GUI"
      ],
      "metadata": {
        "id": "WhwQx3rCY3yb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ Gradio UI (similar layout to your original) ============\n",
        "\n",
        "def toggle_personalization_fields(mode):\n",
        "    show = mode == \"personalized\"\n",
        "    if show:\n",
        "        learning_style, career_goals = load_personalization_preferences()\n",
        "        return (\n",
        "            gr.update(visible=True, value=learning_style),\n",
        "            gr.update(visible=True, value=career_goals)\n",
        "        )\n",
        "    return gr.update(visible=False), gr.update(visible=False)\n",
        "\n",
        "init_preferences_file()\n",
        "default_learning_style, default_career_goals = load_personalization_preferences()\n",
        "\n",
        "with gr.Blocks(css=\".gr-button { width: 100% !important; }\") as demo:\n",
        "    output_md = gr.Markdown(label=\"ğŸ“Š Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±\")\n",
        "\n",
        "    with gr.Row():\n",
        "        profile = gr.Textbox(lines=8, label=\"ğŸ” Î ÏÎ¿Ï†Î¯Î» / Î ÎµÏÎ¹Î³ÏÎ±Ï†Î®\", interactive=True)\n",
        "\n",
        "    with gr.Row():\n",
        "        role = gr.Textbox(lines=1, label=\"ğŸ¯ Î•Ï€Î¹Î»ÎµÎ³Î¼Î­Î½Î¿Ï‚ Î¡ÏŒÎ»Î¿Ï‚ (Ï€ÏÎ¿Î±Î¹ÏÎµÏ„Î¹ÎºÎ¬)\", interactive=True)\n",
        "\n",
        "    with gr.Row():\n",
        "        resume = gr.File(label=\"ğŸ“„ Î’Î¹Î¿Î³ÏÎ±Ï†Î¹ÎºÏŒ (PDF)\", file_types=[\".pdf\"])\n",
        "\n",
        "    with gr.Row():\n",
        "        mode_dropdown = gr.Dropdown(\n",
        "            [\"default\", \"interview\", \"personalized\"],\n",
        "            label=\"Î›ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¯Î±\",\n",
        "            value=\"default\"\n",
        "        )\n",
        "\n",
        "    with gr.Row():\n",
        "        learning_style_input = gr.Dropdown(\n",
        "            choices=[\"visual\", \"auditory\", \"hands-on\"],\n",
        "            label=\"ğŸ“š Î£Ï„Ï…Î» ÎœÎ¬Î¸Î·ÏƒÎ·Ï‚\",\n",
        "            value=default_learning_style,\n",
        "            visible=False\n",
        "        )\n",
        "\n",
        "        career_goals_input = gr.Textbox(\n",
        "            label=\"ğŸ¯ Î£Ï„ÏŒÏ‡Î¿Î¹ ÎšÎ±ÏÎ¹Î­ÏÎ±Ï‚\",\n",
        "            value=default_career_goals,\n",
        "            visible=False\n",
        "        )\n",
        "\n",
        "    mode_dropdown.change(\n",
        "        toggle_personalization_fields,\n",
        "        inputs=[mode_dropdown],\n",
        "        outputs=[learning_style_input, career_goals_input]\n",
        "    )\n",
        "\n",
        "    state = gr.State()\n",
        "\n",
        "    with gr.Row():\n",
        "        submit_btn = gr.Button(\"ğŸš€ Submit\", scale=1)\n",
        "\n",
        "    with gr.Row():\n",
        "        clear_btn = gr.Button(\"ğŸ§¹ Clear\", scale=1)\n",
        "\n",
        "    submit_btn.click(\n",
        "    fn=full_pipeline,\n",
        "          inputs=[\n",
        "              profile, role, resume, state,\n",
        "              mode_dropdown,\n",
        "              learning_style_input,\n",
        "              career_goals_input\n",
        "          ],\n",
        "          outputs=[output_md, state]\n",
        "      )\n",
        "\n",
        "    clear_btn.click(\n",
        "        fn=lambda: (\"\", []),\n",
        "        outputs=[output_md, state]\n",
        "    )"
      ],
      "metadata": {
        "id": "Fu_zbPxZGzQT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Execution"
      ],
      "metadata": {
        "id": "LKWQeEIXY6a4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "id": "n2-2JMdsY0fB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}