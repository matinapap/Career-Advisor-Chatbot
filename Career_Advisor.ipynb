{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdLlyP+ENqtG497GfCjmB5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/matinapap/Career-Advisor-Chatbot/blob/main/Career_Advisor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ğŸ¤– Career Advisor Pipeline â€” Google Colab + Gemini + LangGraph\n",
        "Detailed description for the accompanying notebook / script\n",
        "\n",
        "---\n",
        "\n",
        "## âœ¨ Overview\n",
        "This project implements a **complete career guidance system** running on **Google Colab**, leveraging:\n",
        "\n",
        "- **Gemini (google.generativeai)**\n",
        "- **LangGraph** and modular agents\n",
        "- **RAG using FAISS + HuggingFace embeddings**\n",
        "- **SerpAPI** for course search\n",
        "- **Gradio GUI**\n",
        "\n",
        "The system analyzes user profiles, recommends suitable roles, generates learning plans, provides resume feedback (powered by RAG), and conducts mock interviews.\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§  Pipeline Agents / Nodes\n",
        "\n",
        "### ğŸ” Profile Analyzer\n",
        "- Processes the text-based user profile (optionally including a PDF resume).  \n",
        "- Uses the **Gemini** model to extract skills, experiences, and interests.  \n",
        "- Returns a **detailed narrative description**.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ’¼ Career Suggestion Agent\n",
        "- Produces at least **two recommended career roles**.  \n",
        "- Includes justification, required skills, and steps for progression.  \n",
        "- Supports **fallback parsing** in case of LLM JSON failures.\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“ Learning Path Generator\n",
        "Provides a complete learning plan for a chosen role, including:\n",
        "- technologies  \n",
        "- modules  \n",
        "- duration  \n",
        "- recommended courses (Udemy / YouTube / Coursera)  \n",
        "- progression roadmap  \n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ“„ Resume Advisor (RAG-Powered)\n",
        "- Uses a **FAISS vectorstore**  \n",
        "- Employs **all-MiniLM-L6-v2** embeddings  \n",
        "- Performs similarity search on a local **resume_tips.txt** file  \n",
        "- Produces targeted resume improvements by combining RAG context + LLM reasoning  \n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ—£ï¸ Mock Interview Agent\n",
        "- Generates **realistic mock interview questions**  \n",
        "- Provides model answers and improvement tips  \n",
        "- Adapts to the user profile & chosen role (with RAG support)\n",
        "\n",
        "---\n",
        "\n",
        "### ğŸ§­ Personalized Learning Agent\n",
        "An advanced agent that:\n",
        "- Extracts **skill gaps**  \n",
        "- Builds a **personalized learning plan** using `learning_style` & `career_goals`  \n",
        "- Generates skill keywords and queries **SerpAPI** for online courses  \n",
        "- Saves user preferences to a JSON file  \n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ§© LangGraph Architecture\n",
        "\n",
        "The system consists of 3 separate LangGraph pipelines:\n",
        "\n",
        "### ğŸ”¹ Default Flow  \n",
        "Profile â†’ Role Suggestions â†’ Learning Path\n",
        "\n",
        "### ğŸ”¹ Personalized Flow  \n",
        "Profile â†’ Role Suggestions â†’ Personalized Learning (with skill gaps & preferences)\n",
        "\n",
        "### ğŸ”¹ Interview Flow  \n",
        "Profile â†’ Role Suggestions â†’ Resume Feedback (RAG) â†’ Mock Interview"
      ],
      "metadata": {
        "id": "tOQqwtvyUiaQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Google Drive Conection"
      ],
      "metadata": {
        "id": "j6HQsIcmWYpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  # Î£Ï…Î½Î´Î­ÎµÎ¹ Ï„Î¿ Google Drive Î¼Îµ Ï„Î¿ Ï€ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½ Ï„Î¿Ï… Google Colab Î³Î¹Î± Î½Î± Î±Ï€Î¿ÎºÏ„Î®ÏƒÎ¿Ï…Î¼Îµ Ï€ÏÏŒÏƒÎ²Î±ÏƒÎ· ÏƒÎµ Î±ÏÏ‡ÎµÎ¯Î± Î±Ï€ÏŒ Ï„Î¿Î½ Î»Î¿Î³Î±ÏÎ¹Î±ÏƒÎ¼ÏŒ Î¼Î±Ï‚\n",
        "#  from google.colab import drive\n",
        "#  drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "o0NMD0L3HdmW"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dependecies Installation"
      ],
      "metadata": {
        "id": "cPp-FurYWZ3t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall -y langchain langchain-core langchain-community langchain-openai langchain-text-splitters langgraph pydantic\n",
        "\n",
        "# !pip install \"pydantic>=2.0,<3.0\"\n",
        "\n",
        "# !pip install langchain langchain-community langchain-openai langchain-text-splitters langgraph\n",
        "\n",
        "# !pip install gradio PyPDF2 faiss-cpu sentence-transformers google-generativeai"
      ],
      "metadata": {
        "id": "oi6a_8I-Sug0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "ssNUb2g5WhZ8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gMPVseRWGBVP"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import re\n",
        "import os\n",
        "import traceback\n",
        "from typing import TypedDict, Optional, List, Dict\n",
        "from datetime import datetime\n",
        "import textwrap\n",
        "\n",
        "# === Third-party libs commonly used ===\n",
        "import gradio as gr\n",
        "import PyPDF2\n",
        "import requests\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# === LangChain ===\n",
        "from langchain.tools import tool\n",
        "from langchain_openai import ChatOpenAI # ChatOpenAI moved to langchain_openai in 0.2.x\n",
        "from langchain_core.messages import HumanMessage # HumanMessage moved to langchain_core.messages\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# Embeddings & FAISS RAG\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter # Moved to langchain_text_splitters\n",
        "from langchain_core.documents import Document # Moved to langchain_core.documents\n",
        "from langchain_community.vectorstores import FAISS # Moved to langchain_community.vectorstores\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings # Moved to langchain_community.embeddings\n",
        "\n",
        "from google.colab import userdata\n",
        "import google.generativeai as genai\n",
        "\n",
        "# === Global constants ===\n",
        "PREFS_FILE = \"user_personalization.json\"\n",
        "HISTORY_FILE = \"/content/drive/MyDrive/career_advisor_files/history.json\"\n",
        "RESUME_TIPS_PATH = \"/content/drive/MyDrive/career_advisor_files/resume_tips.txt\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Api Keys Configuration"
      ],
      "metadata": {
        "id": "8FhL7iaSXbMt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key=userdata.get(\"Gemini_Key\"))\n",
        "\n",
        "# print(\"Î”Î¹Î±Î¸Î­ÏƒÎ¹Î¼Î± Î¼Î¿Î½Ï„Î­Î»Î±:\")\n",
        "# for m in genai.list_models():\n",
        "#     methods = getattr(m, \"supported_generation_methods\", [])\n",
        "#     if \"generateContent\" in methods:\n",
        "#         print(\"âœ…\", m.name)\n",
        "\n",
        "model = genai.GenerativeModel(\"gemini-flash-latest\")"
      ],
      "metadata": {
        "id": "Aqk5uB5GGHlQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Î‘ÏÏ‡Î¹ÎºÎ¿Ï€Î¿Î¯Î·ÏƒÎ· Î‘ÏÏ‡ÎµÎ¯Î¿Ï… Î ÏÎ¿Ï„Î¹Î¼Î®ÏƒÎµÏ‰Î½"
      ],
      "metadata": {
        "id": "ClD9DkJXXeEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Initialize preferences file if missing ===\n",
        "def init_preferences_file():\n",
        "    if not os.path.exists(PREFS_FILE):\n",
        "        prefs = {\n",
        "            \"learning_style\": \"visual\",\n",
        "            \"career_goals\": \"ÎÎ± ÎµÏÎ³Î¬Î¶Î¿Î¼Î±Î¹ ÎµÎ¾ Î±Ï€Î¿ÏƒÏ„Î¬ÏƒÎµÏ‰Ï‚ ÎºÎ±Î¹ Î½Î± Î­Ï‡Ï‰ ÎµÏ…Î­Î»Î¹ÎºÏ„Î¿ Ï‰ÏÎ¬ÏÎ¹Î¿.\"\n",
        "        }\n",
        "        with open(PREFS_FILE, \"w\", encoding=\"utf-8\") as f:\n",
        "            json.dump(prefs, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "def save_user_preferences(learning_style: str, career_goals: str):\n",
        "    with open(PREFS_FILE, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump({\"learning_style\": learning_style, \"career_goals\": career_goals}, f, ensure_ascii=False, indent=2)\n",
        "\n",
        "def load_personalization_preferences():\n",
        "    if not os.path.exists(PREFS_FILE):\n",
        "        init_preferences_file()\n",
        "    with open(PREFS_FILE, \"r\", encoding=\"utf-8\") as f:\n",
        "        prefs = json.load(f)\n",
        "    return prefs.get(\"learning_style\", \"visual\"), prefs.get(\"career_goals\", \"\")"
      ],
      "metadata": {
        "id": "OwcTSEXhGQ2P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Î’Î¬ÏƒÎ· Î“Î½ÏÏƒÎ·Ï‚ Î³Î¹Î± Î’Î¹Î¿Î³ÏÎ±Ï†Î¹ÎºÎ¬"
      ],
      "metadata": {
        "id": "bSAU5p6UYC3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === Load resume tips for RAG ===\n",
        "if os.path.exists(RESUME_TIPS_PATH):\n",
        "    try:\n",
        "        with open(RESUME_TIPS_PATH, \"r\", encoding=\"utf-8\") as f:\n",
        "            resume_tips = f.read()\n",
        "    except Exception:\n",
        "        resume_tips = \"\"\n",
        "else:\n",
        "    resume_tips = \"\"\n",
        "\n",
        "# Build small FAISS store from resume tips\n",
        "if resume_tips:\n",
        "    docs = [Document(page_content=resume_tips)]\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "    chunks = splitter.split_documents(docs)\n",
        "    embedding = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "    try:\n",
        "        db = FAISS.from_documents(chunks, embedding)\n",
        "    except Exception:\n",
        "        db = None\n",
        "else:\n",
        "    db = None"
      ],
      "metadata": {
        "id": "O7GeaFQOGUKz"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helpers"
      ],
      "metadata": {
        "id": "2n9SvBywYWL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gemini_prompt(prompt: str, safety_fallback=\"(Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î±Ï€Î¬Î½Ï„Î·ÏƒÎ·)\"):\n",
        "    try:\n",
        "        return model.generate_content(prompt).text\n",
        "    except Exception as e:\n",
        "        return f\"{safety_fallback}\\n\\n(Î£Ï†Î¬Î»Î¼Î±: {e})\""
      ],
      "metadata": {
        "id": "phj2CA5Sn2lw"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(pdf_path: str) -> str:\n",
        "    \"\"\"Î•Î¾Î¬Î³ÎµÎ¹ text Î±Ï€ÏŒ PDF (PyPDF2 fallback).\"\"\"\n",
        "    text = \"\"\n",
        "    try:\n",
        "        with open(pdf_path, \"rb\") as f:\n",
        "            reader = PyPDF2.PdfReader(f)\n",
        "            for page in reader.pages:\n",
        "                text += page.extract_text() or \"\"\n",
        "    except Exception as e:\n",
        "        text = f\"(Î£Ï†Î¬Î»Î¼Î± ÏƒÏ„Î·Î½ Î±Î½Î¬Î³Î½Ï‰ÏƒÎ· PDF: {e})\"\n",
        "    return text"
      ],
      "metadata": {
        "id": "H1uKOt39GYES"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_output(raw_text: str) -> str:\n",
        "    if not raw_text:\n",
        "        return \"(No output)\"\n",
        "    raw_text = str(raw_text)\n",
        "    if raw_text.strip().startswith(\"<!DOCTYPE\") or raw_text.strip().startswith(\"<html\"):\n",
        "        import re\n",
        "        return re.sub(r\"<[^>]*>\", \"\", raw_text)\n",
        "    return raw_text"
      ],
      "metadata": {
        "id": "1zcfEuvcYkrh"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ LLM Wrapper ============\n",
        "\n",
        "def llm_run(prompt: str) -> str:\n",
        "    \"\"\"Unified LLM call for Gemini / LangChain.\"\"\"\n",
        "    try:\n",
        "        if hasattr(model, \"generate_content\"):\n",
        "            return model.generate_content(prompt).text\n",
        "        if hasattr(model, \"predict\"):\n",
        "            return model.predict(prompt)\n",
        "        if hasattr(model, \"generate\"):\n",
        "            messages = [HumanMessage(content=prompt)]\n",
        "            return model.generate(messages).generations[0][0].text\n",
        "        return \"(model Î´ÎµÎ½ Ï…Ï€Î¿ÏƒÏ„Î·ÏÎ¯Î¶ÎµÏ„Î±Î¹)\"\n",
        "    except Exception as e:\n",
        "        return f\"(model error: {e})\""
      ],
      "metadata": {
        "id": "y5PXr2GDGbYw"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tools"
      ],
      "metadata": {
        "id": "XDSQwna9Yazr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ Tools (LangChain-style) ============\n",
        "\n",
        "@tool\n",
        "def search_courses(skill: str, max_results: int = 3) -> str:\n",
        "    \"\"\"\n",
        "    Î‘Î½Î±Î¶Î·Ï„Î¬ online courses Î³Î¹Î± Î­Î½Î± skill (Udemy, Coursera, YouTube) Î¼Î­ÏƒÏ‰ SerpAPI.\n",
        "    Î•Ï€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ markdown list.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        api_key = None\n",
        "        if userdata:\n",
        "            api_key = userdata.get(\"SERPAPI_KEY\")\n",
        "        if not api_key:\n",
        "            api_key = os.environ.get(\"SERPAPI_KEY\")\n",
        "\n",
        "        if not api_key:\n",
        "            return \"ERROR: Missing SerpAPI key.\"\n",
        "        platforms = [\"udemy.com\", \"coursera.org\", \"youtube.com\"]\n",
        "        results_out = []\n",
        "\n",
        "        for site in platforms:\n",
        "            query = requests.utils.requote_uri(f\"{skill} course site:{site}\")\n",
        "            url = f\"https://serpapi.com/search.json?q={query}&api_key={api_key}&num={max_results}\"\n",
        "            try:\n",
        "                r = requests.get(url, timeout=8)\n",
        "                if r.status_code != 200:\n",
        "                    continue\n",
        "                data = r.json().get(\"organic_results\", [])\n",
        "                for item in data[:max_results]:\n",
        "                    title = item.get(\"title\")\n",
        "                    link = item.get(\"link\")\n",
        "                    if title and link:\n",
        "                        results_out.append(f\"- [{title}]({link})\")\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "        return \"\\n\".join(results_out) if results_out else f\"(Î”ÎµÎ½ Î²ÏÎ­Î¸Î·ÎºÎ±Î½ courses Î³Î¹Î± Ï„Î¿ skill: {skill})\"\n",
        "    except Exception as e:\n",
        "        return f\"(search_courses error: {e})\"\n"
      ],
      "metadata": {
        "id": "OwgPbumwYZOB"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class ExtractResumeSkillsInput(BaseModel):\n",
        "#     text: str = Field(description=\"The resume text from which to extract skills.\")\n",
        "\n",
        "# class ResumeSkills(BaseModel):\n",
        "#     skills: List[str] = Field(default_factory=list)\n",
        "\n",
        "# @tool(args_schema=ExtractResumeSkillsInput)\n",
        "# def extract_resume_skills(inputs: ExtractResumeSkillsInput) -> ResumeSkills:\n",
        "#     \"\"\"Extract short skill keywords from resume text and return them as JSON.\"\"\"\n",
        "#     text = inputs.text\n",
        "#     prompt = f\"\"\"\n",
        "# Extract short skill keywords from the resume text below. Return JSON matching this schema:\n",
        "# {ResumeSkills.schema_json()}\n",
        "\n",
        "# Resume:\n",
        "# {text}\n",
        "# \"\"\"\n",
        "#     raw = llm_run(prompt)\n",
        "#     try:\n",
        "#         parsed = json.loads(raw)\n",
        "#         return ResumeSkills(**parsed)\n",
        "#     except Exception:\n",
        "#         maybe = re.findall(r'\\b[A-Za-z0-9.+#\\-]{2,}\\b', text)\n",
        "#         uniq = []\n",
        "#         for w in maybe:\n",
        "#             if w.lower() not in uniq and len(uniq) < 10:\n",
        "#                 uniq.append(w.lower())\n",
        "#         return ResumeSkills(skills=uniq[:8])\n"
      ],
      "metadata": {
        "id": "Hr-uqN24GcHC"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class ExtractSkillKeywordsInput(BaseModel):\n",
        "#     text: str = Field(description=\"The text from which to extract skill keywords.\")\n",
        "\n",
        "# class ExtractedSkills(BaseModel):\n",
        "#     skills: List[str] = Field(default_factory=list)\n",
        "\n",
        "\n",
        "# @tool(args_schema=ExtractSkillKeywordsInput)\n",
        "# def extract_skill_keywords(inputs: ExtractSkillKeywordsInput) -> ExtractedSkills:\n",
        "#     \"\"\"\n",
        "#     Extract up to 4 short English skill keywords from the text.\n",
        "#     Fully relies on the LLM for keyword extraction.\n",
        "#     \"\"\"\n",
        "#     text = inputs.text\n",
        "\n",
        "#     prompt = f\"\"\"\n",
        "# You are a skill extraction assistant.\n",
        "# Extract up to 4 short English skill keywords from the following text.\n",
        "# Return ONLY JSON in the format:\n",
        "# {{\n",
        "#   \"skills\": [\"keyword1\", \"keyword2\", \"keyword3\", \"keyword4\"]\n",
        "# }}\n",
        "\n",
        "# Text:\n",
        "# {text}\n",
        "# \"\"\"\n",
        "\n",
        "#     raw = llm_run(prompt)\n",
        "#     cleaned = re.sub(r'```json|```', '', raw).strip()\n",
        "\n",
        "#     # Î ÏÎ¿ÏƒÏ€Î¬Î¸ÎµÎ¹Î± Î½Î± ÎºÎ¬Î½Î¿Ï…Î¼Îµ parse Ï„Î¿ JSON\n",
        "#     try:\n",
        "#         parsed = json.loads(cleaned)\n",
        "#         skills = parsed.get(\"skills\", [])\n",
        "#     except Exception:\n",
        "#         # Î‘Î½ Ï„Î¿ LLM Î´ÎµÎ½ ÎµÏ€Î¹ÏƒÏ„ÏÎ­ÏˆÎµÎ¹ JSON, ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†Î¿Ï…Î¼Îµ ÎºÎµÎ½Î® Î»Î¯ÏƒÏ„Î±\n",
        "#         skills = []\n",
        "\n",
        "#     # Î•Î¾Î±ÏƒÏ†Î±Î»Î¯Î¶Î¿Ï…Î¼Îµ max 4 skills\n",
        "#     return ExtractedSkills(skills=skills[:4])"
      ],
      "metadata": {
        "id": "OcjDiZ3JMeX_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agent Initialization"
      ],
      "metadata": {
        "id": "LWAhUdELYfnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # ============ Agent Initialization ============\n",
        "# TOOLS = [\n",
        "#     search_courses\n",
        "# ]\n",
        "\n",
        "\n",
        "# def init_agent():\n",
        "#     \"\"\"\n",
        "#     Initialize a LangChain agent configured for function calling.\n",
        "#     Uses ChatOpenAI for function-calling agent behavior where possible.\n",
        "#     \"\"\"\n",
        "#     # If LLM is ChatOpenAI style, use it directly. Else create a minimal wrapper chain.\n",
        "#     if hasattr(model, \"client\") or hasattr(model, \"predict\") or hasattr(model, \"__call__\"):\n",
        "#         # Initialize agent with tools\n",
        "#         try:\n",
        "#             # If LLM is ChatOpenAI instance, pass directly\n",
        "#             agent = initialize_agent(\n",
        "#                 tools=TOOLS,\n",
        "#                 llm=model,\n",
        "#                 agent=AgentType.OPENAI_FUNCTIONS,\n",
        "#                 verbose=False\n",
        "#             )\n",
        "#             return agent\n",
        "#         except Exception as e:\n",
        "#             # fallback: use a simple wrapper agent that will call tools manually\n",
        "#             return None\n",
        "#     return None\n",
        "\n",
        "# AGENT = init_agent()\n"
      ],
      "metadata": {
        "id": "QAzFxvCKGgrC"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Agents"
      ],
      "metadata": {
        "id": "xujToZ4kYpCO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Profile Analyzer"
      ],
      "metadata": {
        "id": "R9c95H5-k9Yu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_profile(user_profile: str) -> str:\n",
        "    prompt = f\"\"\"\n",
        "Î‘Î½Î¬Î»Ï…ÏƒÎµ Ï„Î¿ Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰ Ï€ÏÎ¿Ï†Î¯Î» Ï‡ÏÎ®ÏƒÏ„Î· ÎºÎ±Î¹ Î³ÏÎ¬ÏˆÎµ Î­Î½Î± Î±Î½Î±Î»Ï…Ï„Î¹ÎºÏŒ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ ÏƒÏ„Î± ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬\n",
        "Ï€Î¿Ï… Ï€ÎµÏÎ¹Î³ÏÎ¬Ï†ÎµÎ¹ Ï„Î¹Ï‚ Î´ÎµÎ¾Î¹ÏŒÏ„Î·Ï„ÎµÏ‚, Î³Î½ÏÏƒÎµÎ¹Ï‚ ÎºÎ±Î¹ ÎµÎ½Î´Î¹Î±Ï†Î­ÏÎ¿Î½Ï„Î± Ï„Î¿Ï… Ï‡ÏÎ®ÏƒÏ„Î·.\n",
        "Î ÎµÏÎ¹Î­Î³ÏÎ±ÏˆÎµ Î±Î½Î±Î»Ï…Ï„Î¹ÎºÎ¬ ÎºÎ±Î¹ Ï‡Ï‰ÏÎ¯Ï‚ Î»Î¯ÏƒÏ„ÎµÏ‚.\n",
        "\n",
        "Î ÏÎ¿Ï†Î¯Î»:\n",
        "{user_profile}\n",
        "\"\"\"\n",
        "    return gemini_prompt(prompt)"
      ],
      "metadata": {
        "id": "LeAQTESolASA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Career Suggestions"
      ],
      "metadata": {
        "id": "Xsie6k9blE9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def suggest_careers(skills_summary: str) -> str:\n",
        "    prompt = f\"\"\"\n",
        "ÎœÎµ Î²Î¬ÏƒÎ· Ï„Î¹Ï‚ Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰ Î´ÎµÎ¾Î¹ÏŒÏ„Î·Ï„ÎµÏ‚:\n",
        "\n",
        "{skills_summary}\n",
        "\n",
        "Î“ÏÎ¬ÏˆÎµ Î±Î½Î±Î»Ï…Ï„Î¹ÎºÎ¬, ÏƒÎµ ÏƒÏ…Î½ÎµÎºÏ„Î¹ÎºÏŒ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ ÏƒÏ„Î± ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬:\n",
        "- 2 ÎºÎ±Ï„Î¬Î»Î»Î·Î»Î¿Ï…Ï‚ ÎµÏ€Î±Î³Î³ÎµÎ»Î¼Î±Ï„Î¹ÎºÎ¿ÏÏ‚ ÏÏŒÎ»Î¿Ï…Ï‚\n",
        "- Î“Î¹Î±Ï„Î¯ Ï„Î±Î¹ÏÎ¹Î¬Î¶Î¿Ï…Î½\n",
        "- Î‘Ï€Î±ÏÎ±Î¯Ï„Î·Ï„ÎµÏ‚ Î´ÎµÎ¾Î¹ÏŒÏ„Î·Ï„ÎµÏ‚\n",
        "- Î¤Î¹ Î¸Î± Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± ÎºÎ¬Î½ÎµÎ¹ Î¿ Ï‡ÏÎ®ÏƒÏ„Î·Ï‚ Î³Î¹Î± Î½Î± Ï€ÏÎ¿Ï‡Ï‰ÏÎ®ÏƒÎµÎ¹\n",
        "\"\"\"\n",
        "    return gemini_prompt(prompt)"
      ],
      "metadata": {
        "id": "gp_RrEv3lHPd"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Suggest Learning Path"
      ],
      "metadata": {
        "id": "Kk3mPaBUlMb1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def suggest_learning_path(role: str) -> str:\n",
        "    prompt = f\"\"\"\n",
        "Î ÏÏŒÏ„ÎµÎ¹Î½Îµ Î­Î½Î± Î±Î½Î±Î»Ï…Ï„Î¹ÎºÏŒ Ï€Î»Î¬Î½Î¿ ÎµÎºÎ¼Î¬Î¸Î·ÏƒÎ·Ï‚ Î³Î¹Î± Ï„Î¿Î½ ÏÏŒÎ»Î¿: {role}.\n",
        "Î£Ï…Î¼Ï€ÎµÏÎ¯Î»Î±Î²Îµ:\n",
        "- Î¤ÎµÏ‡Î½Î¿Î»Î¿Î³Î¯ÎµÏ‚ / Î­Î½Î½Î¿Î¹ÎµÏ‚ Ï€Î¿Ï… Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± Î¼Î¬Î¸ÎµÎ¹\n",
        "- Î ÏÎ¿Ï„ÎµÎ¹Î½ÏŒÎ¼ÎµÎ½Î± online Î¼Î±Î¸Î®Î¼Î±Ï„Î± (Coursera, YouTube)\n",
        "- Î•ÎºÏ„Î¹Î¼ÏÎ¼ÎµÎ½Î¿Ï‚ Ï‡ÏÏŒÎ½Î¿Ï‚ Î³Î¹Î± ÎºÎ¬Î¸Îµ Î¸Î­Î¼Î±\n",
        "Î“ÏÎ¬ÏˆÎµ ÏƒÎµ ÎµÎ»Î»Î·Î½Î¹ÎºÏŒ ÏƒÏ…Î½ÎµÎºÏ„Î¹ÎºÏŒ ÎºÎµÎ¯Î¼ÎµÎ½Î¿, Ï‡Ï‰ÏÎ¯Ï‚ bullets.\n",
        "\"\"\"\n",
        "    return gemini_prompt(prompt)"
      ],
      "metadata": {
        "id": "ngpxM48wlS_i"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Suggest Resume Improvements"
      ],
      "metadata": {
        "id": "sxGiI_PvlW0r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def suggest_resume_improvements(resume_text: str) -> str:\n",
        "    \"\"\"\n",
        "    Î‘Î¾Î¹Î¿Î»Î¿Î³ÎµÎ¯ Ï„Î¿ Î²Î¹Î¿Î³ÏÎ±Ï†Î¹ÎºÏŒ, ÎºÎ¬Î½ÎµÎ¹ RAG Î¼Îµ db Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ ÎºÎ±Î¹ ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹\n",
        "    Î±Î½Î±Î»Ï…Ï„Î¹ÎºÎ¬ ÏƒÏ‡ÏŒÎ»Î¹Î± ÎºÎ±Î¹ Ï€ÏÎ¿Ï„Î¬ÏƒÎµÎ¹Ï‚ Î²ÎµÎ»Ï„Î¯Ï‰ÏƒÎ·Ï‚ ÏƒÏ„Î± ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬, ÏƒÎµ Ï€Î»Î®ÏÎµÏ‚ ÎºÎµÎ¯Î¼ÎµÎ½Î¿.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        context = \"\"\n",
        "        if db:\n",
        "            try:\n",
        "                relevant = db.similarity_search(resume_text, k=3)\n",
        "                context = \"\\n\\n\".join([d.page_content for d in relevant])\n",
        "            except Exception:\n",
        "                context = \"\"\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎµ Ï„Î¿ Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰ Î²Î¹Î¿Î³ÏÎ±Ï†Î¹ÎºÏŒ ÎºÎ±Î¹ Î´ÏÏƒÎµ **Î±Î½Î±Î»Ï…Ï„Î¹ÎºÎ¬ ÏƒÏ‡ÏŒÎ»Î¹Î±** ÏƒÏ„Î± ÎµÎ»Î»Î·Î½Î¹ÎºÎ¬.\n",
        "Î£Ï…Î¼Ï€ÎµÏÎ¹Î­Î»Î±Î²Îµ:\n",
        "- Î¤Î¹ Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³ÎµÎ¯ ÎºÎ±Î»Î¬ ÎºÎ±Î¹ Ï„Î¹ ÏŒÏ‡Î¹\n",
        "- Î ÏÎ¿Ï„Î¬ÏƒÎµÎ¹Ï‚ Î²ÎµÎ»Ï„Î¯Ï‰ÏƒÎ·Ï‚ Î³Î¹Î± ÎºÎ¬Î¸Îµ ÎµÎ½ÏŒÏ„Î·Ï„Î± (Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·, Î•ÏÎ³Î±ÏƒÎ¹Î±ÎºÎ® ÎµÎ¼Ï€ÎµÎ¹ÏÎ¯Î±, Î”ÎµÎ¾Î¹ÏŒÏ„Î·Ï„ÎµÏ‚)\n",
        "- Î£Ï…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î¿ ÎºÎµÎ¯Î¼ÎµÎ½Î¿ Ï€Î¿Ï… Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Ï€ÏÎ¿ÏƒÏ„ÎµÎ¸ÎµÎ¯ Î® Î±Î½Ï„Î¹ÎºÎ±Ï„Î±ÏƒÏ„Î±Î¸ÎµÎ¯\n",
        "\n",
        "Î’Î¹Î¿Î³ÏÎ±Ï†Î¹ÎºÏŒ:\n",
        "{resume_text}\n",
        "\n",
        "ÎŸÎ´Î·Î³Î¯ÎµÏ‚ / Î£Ï…Î¼Ï€Î»Î·ÏÏ‰Î¼Î±Ï„Î¹ÎºÏŒ context:\n",
        "{context}\n",
        "\"\"\"\n",
        "        raw = llm_run(prompt)\n",
        "\n",
        "        return clean_output(raw)\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"(Î£Ï†Î¬Î»Î¼Î± suggest_resume_improvements: {e})\"\n"
      ],
      "metadata": {
        "id": "h5kA_x5xlcuV"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Interview Agent"
      ],
      "metadata": {
        "id": "3YOlWXONlfYD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def interview_agent(user_profile: str, chosen_role: str, chat_context: str = \"\", resume_text: Optional[str] = None) -> str:\n",
        "    \"\"\"\n",
        "    Î•Ï„Î¿Î¹Î¼Î¬Î¶ÎµÎ¹ mock ÏƒÏ…Î½Î­Î½Ï„ÎµÏ…Î¾Î· Î¼Îµ Ï€Î»Î®ÏÎµÎ¹Ï‚ ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚ ÎºÎ±Î¹ Î±Î½Î±Î»Ï…Ï„Î¹ÎºÎ­Ï‚ ÎµÎ½Î´ÎµÎ¹ÎºÏ„Î¹ÎºÎ­Ï‚ Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚.\n",
        "    Î— Î­Î¾Î¿Î´Î¿Ï‚ ÎµÎ¯Î½Î±Î¹ human-readable ÎºÎµÎ¯Î¼ÎµÎ½Î¿, ÏŒÏ‡Î¹ Î±Ï€Î»ÏÏ‚ Î»Î¯ÏƒÏ„ÎµÏ‚.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        skills_summary = analyze_profile(user_profile + \"\\n\\n\" + chat_context)\n",
        "        rag_context = \"\"\n",
        "        if resume_text and db:\n",
        "            try:\n",
        "                relevant = db.similarity_search(resume_text, k=3)\n",
        "                rag_context = \"\\n\\n\".join([d.page_content for d in relevant])\n",
        "            except Exception:\n",
        "                rag_context = \"\"\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "Î”Î·Î¼Î¹Î¿ÏÏÎ³Î·ÏƒÎµ Î¼Î¹Î± mock ÏƒÏ…Î½Î­Î½Ï„ÎµÏ…Î¾Î· Î³Î¹Î± Ï„Î¿Î½ Ï‡ÏÎ®ÏƒÏ„Î· Î¼Îµ Î²Î¬ÏƒÎ· Ï„Î± Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰ ÏƒÏ„Î¿Î¹Ï‡ÎµÎ¯Î±.\n",
        "Î£Ï…Î¼Ï€ÎµÏÎ¹Î­Î»Î±Î²Îµ **Î±Î½Î±Î»Ï…Ï„Î¹ÎºÎ­Ï‚ Î±Ï€Î±Î½Ï„Î®ÏƒÎµÎ¹Ï‚**, ÎµÏ€ÎµÎ¾Î·Î³Î®ÏƒÎµÎ¹Ï‚ ÎºÎ±Î¹ tips Î³Î¹Î± ÎºÎ¬Î¸Îµ ÎµÏÏÏ„Î·ÏƒÎ·.\n",
        "\n",
        "Î ÏÎ¿Ï†Î¯Î»:\n",
        "{user_profile}\n",
        "\n",
        "Î¡ÏŒÎ»Î¿Ï‚:\n",
        "{chosen_role}\n",
        "\n",
        "Î”ÎµÎ¾Î¹ÏŒÏ„Î·Ï„ÎµÏ‚:\n",
        "{skills_summary}\n",
        "\n",
        "Î’Î¹Î¿Î³ÏÎ±Ï†Î¹ÎºÏŒ / context:\n",
        "{rag_context}\n",
        "\n",
        "ÎœÎ¿ÏÏ†Î®:\n",
        "1. Î•ÏÏÏ„Î·ÏƒÎ·: ...\n",
        "   Î‘Ï€Î¬Î½Ï„Î·ÏƒÎ·: ...\n",
        "   (Î ÏÏŒÏƒÎ¸ÎµÏ„ÎµÏ‚ ÏƒÏ…Î¼Î²Î¿Ï…Î»Î­Ï‚ Î® ÎµÎ¾Î·Î³Î®ÏƒÎµÎ¹Ï‚)\n",
        "\"\"\"\n",
        "        raw = llm_run(prompt)\n",
        "        return clean_output(raw)\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"(Î£Ï†Î¬Î»Î¼Î± interview_agent: {e})\""
      ],
      "metadata": {
        "id": "iFeJEcoLlnJE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Personalized Learning"
      ],
      "metadata": {
        "id": "9bN7I9tLlqBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def personalized_learning(user_skills_text, target_role, personalization_info):\n",
        "    try:\n",
        "        prompt_role_desc = f\"\"\"\n",
        "Î”ÏÏƒÎµ Ï€ÎµÏÎ¹Î³ÏÎ±Ï†Î® Î³Î¹Î± Ï„Î¿Î½ ÏÏŒÎ»Î¿: {target_role}\n",
        "Î ÎµÏÎ¹Î­Î³ÏÎ±ÏˆÎµ:\n",
        "- Î¤Î¹ ÎºÎ±Î¸Î®ÎºÎ¿Î½Ï„Î± Î­Ï‡ÎµÎ¹\n",
        "- Î Î¿Î¹ÎµÏ‚ Ï„ÎµÏ‡Î½Î¿Î»Î¿Î³Î¯ÎµÏ‚ / Î´ÎµÎ¾Î¹ÏŒÏ„Î·Ï„ÎµÏ‚ Î±Ï€Î±Î¹Ï„Î¿ÏÎ½Ï„Î±Î¹\n",
        "\"\"\"\n",
        "        role_description = gemini_prompt(prompt_role_desc)\n",
        "\n",
        "        prompt_gap = f\"\"\"\n",
        "Î£ÏÎ³ÎºÏÎ¹Î½Îµ Ï„Î¹Ï‚ Ï€Î±ÏÎ±ÎºÎ¬Ï„Ï‰ Î´ÎµÎ¾Î¹ÏŒÏ„Î·Ï„ÎµÏ‚ Ï„Î¿Ï… Ï‡ÏÎ®ÏƒÏ„Î· Î¼Îµ Ï„Î¹Ï‚ Î±Ï€Î±Î¹Ï„Î®ÏƒÎµÎ¹Ï‚ Ï„Î¿Ï… ÏÏŒÎ»Î¿Ï…:\n",
        "\n",
        "--- Î”ÎµÎ¾Î¹ÏŒÏ„Î·Ï„ÎµÏ‚ Î§ÏÎ®ÏƒÏ„Î· ---\n",
        "{user_skills_text}\n",
        "\n",
        "--- Î ÎµÏÎ¹Î³ÏÎ±Ï†Î® Î¡ÏŒÎ»Î¿Ï… ---\n",
        "{role_description}\n",
        "\n",
        "Î’ÏÎµÏ‚:\n",
        "- Î Î¿Î¹ÎµÏ‚ Î´ÎµÎ¾Î¹ÏŒÏ„Î·Ï„ÎµÏ‚ Î»ÎµÎ¯Ï€Î¿Ï…Î½;\n",
        "- Î£Îµ Ï€Î¿Î¹ÎµÏ‚ ÎµÎ¯Î½Î±Î¹ Î±ÏÏ‡Î¬ÏÎ¹Î¿Ï‚;\n",
        "- Î Î¿Î¹Î± ÎµÎ¯Î½Î±Î¹ Ï„Î± ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÏŒÏ„ÎµÏÎ± gaps Î³Î¹Î± Î½Î± ÎºÎ±Î»ÏÏˆÎµÎ¹;\n",
        "Î”ÏÏƒÎµ Ï‰Ï‚ Î»Î¯ÏƒÏ„Î±.\n",
        "\"\"\"\n",
        "        skill_gaps = gemini_prompt(prompt_gap)\n",
        "\n",
        "        prompt_learning = f\"\"\"\n",
        "ÎŸ Ï‡ÏÎ®ÏƒÏ„Î·Ï‚ Î¸Î­Î»ÎµÎ¹ Î½Î± Î³Î¯Î½ÎµÎ¹: {target_role}\n",
        "Î”Î¯Î½ÎµÎ¹ Î­Î¼Ï†Î±ÏƒÎ· ÏƒÎµ:\n",
        "- Learning style: {personalization_info.get('learning_style','-')}\n",
        "- Career goals: {personalization_info.get('career_goals','-')}\n",
        "\n",
        "Î’Î¿Î®Î¸Î·ÏƒÎ­ Ï„Î¿Î½ Î½Î± Î¼Î¬Î¸ÎµÎ¹ ÏŒ,Ï„Î¹ Ï„Î¿Ï… Î»ÎµÎ¯Ï€ÎµÎ¹: {skill_gaps}\n",
        "\n",
        "Î¦Ï„Î¹Î¬Î¾Îµ Î­Î½Î± Ï€Î»Î¬Î½Î¿ ÎµÎºÎ¼Î¬Î¸Î·ÏƒÎ·Ï‚ (Î¸ÎµÎ¼Î±Ï„Î¹ÎºÏŒ), ÎºÎ±Î¹ Î´ÏÏƒÎµ:\n",
        "- Î¤ÎµÏ‡Î½Î¿Î»Î¿Î³Î¯ÎµÏ‚ Î® Î­Î½Î½Î¿Î¹ÎµÏ‚ Ï€ÏÎ¿Ï‚ ÎµÎºÎ¼Î¬Î¸Î·ÏƒÎ·\n",
        "- Î ÏÎ¿Ï„Î¬ÏƒÎµÎ¹Ï‚ Î¼Î±Î¸Î·Î¼Î¬Ï„Ï‰Î½ Î±Ï€ÏŒ Coursera, YouTube\n",
        "- Î ÏÎ¿Ï„ÎµÎ¹Î½ÏŒÎ¼ÎµÎ½Î¿ Ï‡ÏÏŒÎ½Î¿Ï‚ Î±Î½Î¬ Î¸Î­Î¼Î±\n",
        "\"\"\"\n",
        "        learning_plan = gemini_prompt(prompt_learning)\n",
        "\n",
        "        prompt_skills = f\"\"\"\n",
        "Î•Î¯ÏƒÎ±Î¹ Î²Î¿Î·Î¸ÏŒÏ‚ Î³Î¹Î± Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ· Î¼Î±Î¸Î·Î¼Î¬Ï„Ï‰Î½.\n",
        "Î‘Ï€ÏŒ Ï„Î·Î½ Î±Î½Î¬Î»Ï…ÏƒÎ· Î´ÎµÎ¾Î¹Î¿Ï„Î®Ï„Ï‰Î½ ÎµÎ¾Î¬Î³ÎµÎ¹Ï‚ Î­Ï‰Ï‚ 4 ÏƒÎ·Î¼Î±Î½Ï„Î¹ÎºÎ­Ï‚ Î´ÎµÎ¾Î¹ÏŒÏ„Î·Ï„ÎµÏ‚.\n",
        "ÎœÎµÏ„Î­Ï„ÏÎµÏˆÎµ Ï„Î¹Ï‚ ÏƒÎµ ÏƒÏÎ½Ï„Î¿Î¼Î± Î±Î³Î³Î»Î¹ÎºÎ¬ keywords.\n",
        "Î‘Ï€Î¬Î½Ï„Î·ÏƒÎµ ÏƒÎµ JSON, Ï€Ï‡:\n",
        "{{\n",
        "  \"skills\": [\"python\", \"sql\"]\n",
        "}}\n",
        "\n",
        "Skill gaps:\n",
        "{skill_gaps}\n",
        "\n",
        "Î¡ÏŒÎ»Î¿Ï‚:\n",
        "{target_role}\n",
        "\"\"\"\n",
        "        raw_skills = gemini_prompt(prompt_skills)\n",
        "        import json, re\n",
        "        cleaned = re.sub(r'```json|```', '', raw_skills).strip()\n",
        "        try:\n",
        "            agent_output = json.loads(cleaned)\n",
        "            skills = agent_output.get(\"skills\", [])\n",
        "        except Exception:\n",
        "            skills = []\n",
        "        if not skills:\n",
        "            skills = [\"python\", \"sql\", \"data analysis\", \"excel\"]\n",
        "\n",
        "        courses_output = \"\"\n",
        "        for skill in skills:\n",
        "            try:\n",
        "                results = search_courses.invoke({\"skill\": skill, \"max_results\": 3})\n",
        "            except Exception:\n",
        "                results = \"(Î£Ï†Î¬Î»Î¼Î± ÏƒÏ„Î·Î½ Î±Î½Î±Î¶Î®Ï„Î·ÏƒÎ· Î¼Î±Î¸Î·Î¼Î¬Ï„Ï‰Î½)\"\n",
        "            courses_output += f\"### {skill}\\n{results}\\n\\n\"\n",
        "\n",
        "\n",
        "        return f\"\"\"\n",
        "## ğŸ¯ Î¡ÏŒÎ»Î¿Ï‚: {target_role}\n",
        "\n",
        "## ğŸ” Î‘Î½Î¬Î»Ï…ÏƒÎ· Skill Gaps\n",
        "{skill_gaps}\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“ Î ÏÎ¿ÏƒÏ‰Ï€Î¿Ï€Î¿Î¹Î·Î¼Î­Î½Î¿ Î Î»Î¬Î½Î¿ Î•ÎºÎ¼Î¬Î¸Î·ÏƒÎ·Ï‚\n",
        "{learning_plan}\n",
        "\n",
        "---\n",
        "\n",
        "## ğŸ“ Î ÏÎ¿Ï„ÎµÎ¹Î½ÏŒÎ¼ÎµÎ½Î± ÎœÎ±Î¸Î®Î¼Î±Ï„Î±\n",
        "{courses_output}\n",
        "\"\"\"\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        return f\"(Error in personalized_learning_with_courses: {e})\\n{traceback.format_exc()}\""
      ],
      "metadata": {
        "id": "GhNLJStoGr8U"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LangGraph Agent Flow"
      ],
      "metadata": {
        "id": "s7Fr-EW0YuWJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# === LangGraph Agent Flow ===\n",
        "class AgentState(TypedDict):\n",
        "    profile: str\n",
        "    resume_text: str\n",
        "    role: str\n",
        "    skills: str\n",
        "    suggested_roles: str\n",
        "    learning_plan: str\n",
        "    resume_feedback: str\n",
        "    interview_questions: str\n",
        "    learning_style: str\n",
        "    career_goals: str\n",
        "\n",
        "def node_wrapper(output_key, func, *input_keys):\n",
        "    \"\"\"\n",
        "    Î“ÎµÎ½Î¹ÎºÏŒÏ‚ decorator Î³Î¹Î± ÎºÏŒÎ¼Î²Î¿Ï…Ï‚ LangGraph.\n",
        "    ÎšÎ±Î»ÎµÎ¯ Ï„Î· function Î¼Îµ Ï„Î± input keys Î±Ï€ÏŒ Ï„Î¿ state ÎºÎ±Î¹ ÎµÎ½Î·Î¼ÎµÏÏÎ½ÎµÎ¹ Ï„Î¿ output_key.\n",
        "    \"\"\"\n",
        "    def wrapper(state: AgentState):\n",
        "        try:\n",
        "            inputs = [state.get(k, \"\") for k in input_keys]\n",
        "            state[output_key] = func(*inputs)\n",
        "        except Exception as e:\n",
        "            state[output_key] = f\"(Î£Ï†Î¬Î»Î¼Î± ÏƒÏ„Î¿ {output_key}: {e})\"\n",
        "        return state\n",
        "    return wrapper\n",
        "\n",
        "\n",
        "# === Agents ===\n",
        "\n",
        "analyze_profile_node = node_wrapper(\"skills\", analyze_profile, \"profile\")\n",
        "\n",
        "def suggest_roles_node(state: AgentState):\n",
        "    try:\n",
        "        output = suggest_careers(state.get(\"skills\", \"\"))\n",
        "        output_clean = clean_output(output)\n",
        "\n",
        "        try:\n",
        "            roles = json.loads(output_clean)\n",
        "            state[\"suggested_roles\"] = roles\n",
        "            if not state.get(\"role\") and roles:\n",
        "                state[\"role\"] = roles[0].get(\"title\", \"No role\")\n",
        "        except json.JSONDecodeError:\n",
        "            state[\"suggested_roles\"] = output_clean\n",
        "            if not state.get(\"role\"):\n",
        "                first_role = re.search(r\"1\\.\\s+(.*?)\\n\", output_clean)\n",
        "                state[\"role\"] = first_role.group(1).strip() if first_role else \"No role\"\n",
        "\n",
        "    except Exception as e:\n",
        "        state[\"suggested_roles\"] = f\"(Î£Ï†Î¬Î»Î¼Î± ÏƒÏ„Î¿ suggest_roles_node: {e})\"\n",
        "        if not state.get(\"role\"):\n",
        "            state[\"role\"] = \"No role\"\n",
        "    return state\n",
        "\n",
        "\n",
        "learning_path_node = node_wrapper(\"learning_plan\", suggest_learning_path, \"role\")\n",
        "\n",
        "personalized_learning_node = node_wrapper(\n",
        "    \"learning_plan\",\n",
        "    lambda skills, role, learning_style, career_goals: personalized_learning(\n",
        "        skills,\n",
        "        role,\n",
        "        {\n",
        "            \"learning_style\": learning_style,\n",
        "            \"career_goals\": career_goals\n",
        "        }\n",
        "    ),\n",
        "    \"skills\", \"role\", \"learning_style\", \"career_goals\"\n",
        ")\n",
        "\n",
        "\n",
        "def resume_feedback_node(state: AgentState):\n",
        "    try:\n",
        "        if state.get(\"resume_text\"):\n",
        "            feedback = suggest_resume_improvements(state[\"resume_text\"])\n",
        "            state[\"resume_feedback\"] = clean_output(feedback)\n",
        "        else:\n",
        "            state[\"resume_feedback\"] = \"(Î”ÎµÎ½ Ï…Ï€Î¿Î²Î»Î®Î¸Î·ÎºÎµ Î²Î¹Î¿Î³ÏÎ±Ï†Î¹ÎºÏŒ)\"\n",
        "    except Exception as e:\n",
        "        state[\"resume_feedback\"] = f\"(Î£Ï†Î¬Î»Î¼Î± resume_feedback_node: {e})\"\n",
        "    return state\n",
        "\n",
        "interview_node = node_wrapper(\n",
        "    \"interview_questions\",\n",
        "    lambda profile, role, resume_text: clean_output(\n",
        "        interview_agent(profile, role, chat_context=\"\", resume_text=resume_text or profile)\n",
        "    ),\n",
        "    \"profile\", \"role\", \"resume_text\"\n",
        ")\n",
        "\n",
        "\n",
        "# === Graphs ===\n",
        "\n",
        "# Default Flow\n",
        "builder_default = StateGraph(AgentState)\n",
        "builder_default.add_node(\"AnalyzeProfile\", analyze_profile_node)\n",
        "builder_default.add_node(\"SuggestRoles\", suggest_roles_node)\n",
        "builder_default.add_node(\"LearningPath\", learning_path_node)\n",
        "builder_default.add_edge(\"AnalyzeProfile\", \"SuggestRoles\")\n",
        "builder_default.add_edge(\"SuggestRoles\", \"LearningPath\")\n",
        "builder_default.add_edge(\"LearningPath\", END)\n",
        "builder_default.set_entry_point(\"AnalyzeProfile\")\n",
        "default_graph = builder_default.compile()\n",
        "\n",
        "# Personalized Flow\n",
        "builder_personalized = StateGraph(AgentState)\n",
        "builder_personalized.add_node(\"AnalyzeProfile\", analyze_profile_node)\n",
        "builder_personalized.add_node(\"SuggestRoles\", suggest_roles_node)\n",
        "builder_personalized.add_node(\"PersonalizedLearning\", personalized_learning_node)\n",
        "builder_personalized.add_edge(\"AnalyzeProfile\", \"SuggestRoles\")\n",
        "builder_personalized.add_edge(\"SuggestRoles\", \"PersonalizedLearning\")\n",
        "builder_personalized.add_edge(\"PersonalizedLearning\", END)\n",
        "builder_personalized.set_entry_point(\"AnalyzeProfile\")\n",
        "personalized_graph = builder_personalized.compile()\n",
        "\n",
        "# Interview Flow\n",
        "builder_interview = StateGraph(AgentState)\n",
        "builder_interview.add_node(\"AnalyzeProfile\", analyze_profile_node)\n",
        "builder_interview.add_node(\"SuggestRoles\", suggest_roles_node)\n",
        "builder_interview.add_node(\"ResumeFeedback\", resume_feedback_node)\n",
        "builder_interview.add_node(\"Interview\", interview_node)\n",
        "builder_interview.add_edge(\"AnalyzeProfile\", \"SuggestRoles\")\n",
        "builder_interview.add_edge(\"SuggestRoles\", \"ResumeFeedback\")\n",
        "builder_interview.add_edge(\"ResumeFeedback\", \"Interview\")\n",
        "builder_interview.add_edge(\"Interview\", END)\n",
        "builder_interview.set_entry_point(\"AnalyzeProfile\")\n",
        "interview_graph = builder_interview.compile()\n"
      ],
      "metadata": {
        "id": "Vhmq0Ft0GvBk"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pipeline"
      ],
      "metadata": {
        "id": "eQ4_-l_DYxWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ Orchestrator: full_pipeline (like original but agentic) ============\n",
        "\n",
        "def full_pipeline(\n",
        "    user_profile: str,\n",
        "    chosen_role: str = \"\",\n",
        "    resume_file=None,\n",
        "    chat_history_messages: Optional[list] = None,\n",
        "    mode = \"default\",\n",
        "    learning_style: Optional[str] = None,\n",
        "    career_goals: Optional[str] = None,\n",
        "    personalized: bool = False\n",
        "):\n",
        "    # Load personalization defaults if needed\n",
        "    ls, cg = load_personalization_preferences()\n",
        "    learning_style = learning_style or ls\n",
        "    career_goals = career_goals or cg\n",
        "\n",
        "    # === Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± Î’Î¹Î¿Î³ÏÎ±Ï†Î¹ÎºÎ¿Ï (PDF) ===\n",
        "    resume_text = \"\"\n",
        "    resume_clean = \"\"\n",
        "    if resume_file:\n",
        "        try:\n",
        "            resume_text = extract_text_from_pdf(resume_file.name)\n",
        "            resume_clean = clean_output(resume_text)\n",
        "            user_profile += f\"\\n\\n{resume_clean}\"\n",
        "        except Exception as e:\n",
        "            resume_text = f\"(Î£Ï†Î¬Î»Î¼Î± PDF: {e})\"\n",
        "            resume_clean = resume_text\n",
        "\n",
        "    # initial state\n",
        "    initial_state: AgentState = AgentState(\n",
        "        profile=user_profile,\n",
        "        resume_text=resume_text,\n",
        "        role=chosen_role or \"\",\n",
        "        skills=\"\",\n",
        "        suggested_roles=\"\",\n",
        "        learning_plan=\"\",\n",
        "        resume_feedback=\"\",\n",
        "        interview_questions=\"\",\n",
        "        learning_style=learning_style,\n",
        "        career_goals=career_goals\n",
        "    )\n",
        "\n",
        "   # ============== Î•Ï€Î¹Î»Î¿Î³Î® Graph Î±Î½Î¬ mode ==============\n",
        "    if mode == \"default\":\n",
        "      final_state = default_graph.invoke(initial_state)\n",
        "\n",
        "      if chosen_role.strip():\n",
        "          result_markdown = f\"\"\"\n",
        "  ## ğŸ§  Î‘Î½Î¬Î»Ï…ÏƒÎ· Î”ÎµÎ¾Î¹Î¿Ï„Î®Ï„Ï‰Î½\n",
        "  {final_state['skills']}\n",
        "\n",
        "  ## ğŸ“ Î ÏÎ¿Ï„ÎµÎ¹Î½ÏŒÎ¼ÎµÎ½Î¿ Î Î»Î¬Î½Î¿ Î•ÎºÎ¼Î¬Î¸Î·ÏƒÎ·Ï‚\n",
        "  {final_state['learning_plan']}\n",
        "  \"\"\"\n",
        "      else:\n",
        "          result_markdown = f\"\"\"\n",
        "  ## ğŸ§  Î‘Î½Î¬Î»Ï…ÏƒÎ· Î”ÎµÎ¾Î¹Î¿Ï„Î®Ï„Ï‰Î½\n",
        "  {final_state['skills']}\n",
        "\n",
        "  ## ğŸ’¼ Î ÏÎ¿Ï„ÎµÎ¹Î½ÏŒÎ¼ÎµÎ½Î¿Î¹ Î¡ÏŒÎ»Î¿Î¹\n",
        "  {final_state['suggested_roles']}\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "    elif mode == \"personalized\":\n",
        "      final_state = personalized_graph.invoke(initial_state)\n",
        "      save_user_preferences(learning_style, career_goals)\n",
        "      result_markdown = final_state[\"learning_plan\"]\n",
        "    elif mode == \"interview\":\n",
        "      final_state = interview_graph.invoke(initial_state)\n",
        "      parts = []\n",
        "\n",
        "      # Resume feedback\n",
        "      resume_feedback = final_state.get(\"resume_feedback\") or \"(Î”ÎµÎ½ Ï…Ï€Î¿Î²Î»Î®Î¸Î·ÎºÎµ Î® ÏƒÏ†Î¬Î»Î¼Î± ÏƒÏ„Î¿ Î²Î¹Î¿Î³ÏÎ±Ï†Î¹ÎºÏŒ)\"\n",
        "      parts.append(f\"## âœï¸ Î£Ï‡ÏŒÎ»Î¹Î± Î³Î¹Î± Ï„Î¿ Î’Î¹Î¿Î³ÏÎ±Ï†Î¹ÎºÏŒ\\n{resume_feedback}\")\n",
        "\n",
        "      # Interview questions\n",
        "      interview_text = final_state.get(\"interview_questions\") or \"(Î”ÎµÎ½ Ï…Ï€Î¬ÏÏ‡Î¿Ï…Î½ ÎµÏÏ‰Ï„Î®ÏƒÎµÎ¹Ï‚ ÏƒÏ…Î½Î­Î½Ï„ÎµÏ…Î¾Î·Ï‚)\"\n",
        "      parts.append(f\"## ğŸ¤ Mock Î£Ï…Î½Î­Î½Ï„ÎµÏ…Î¾Î·\\n{interview_text}\")\n",
        "\n",
        "      result_markdown = \"\\n\\n\".join(parts)\n",
        "    else:\n",
        "      result_markdown = \"âš ï¸ ÎœÎ· Ï…Ï€Î¿ÏƒÏ„Î·ÏÎ¹Î¶ÏŒÎ¼ÎµÎ½Î· Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¯Î±.\"\n",
        "      final_state = {}\n",
        "\n",
        "    print(result_markdown)\n",
        "\n",
        "    return result_markdown, final_state\n"
      ],
      "metadata": {
        "id": "_O3F_Q6eGwuE"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GUI"
      ],
      "metadata": {
        "id": "WhwQx3rCY3yb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============ Gradio UI (similar layout to your original) ============\n",
        "\n",
        "def toggle_personalization_fields(mode):\n",
        "    show = mode == \"personalized\"\n",
        "    if show:\n",
        "        learning_style, career_goals = load_personalization_preferences()\n",
        "        return (\n",
        "            gr.update(visible=True, value=learning_style),\n",
        "            gr.update(visible=True, value=career_goals)\n",
        "        )\n",
        "    return gr.update(visible=False), gr.update(visible=False)\n",
        "\n",
        "init_preferences_file()\n",
        "default_learning_style, default_career_goals = load_personalization_preferences()\n",
        "\n",
        "with gr.Blocks(css=\".gr-button { width: 100% !important; }\") as demo:\n",
        "    output_md = gr.Markdown(label=\"ğŸ“Š Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±\")\n",
        "\n",
        "    with gr.Row():\n",
        "        profile = gr.Textbox(lines=8, label=\"ğŸ” Î ÏÎ¿Ï†Î¯Î» / Î ÎµÏÎ¹Î³ÏÎ±Ï†Î®\", interactive=True)\n",
        "\n",
        "    with gr.Row():\n",
        "        role = gr.Textbox(lines=1, label=\"ğŸ¯ Î•Ï€Î¹Î»ÎµÎ³Î¼Î­Î½Î¿Ï‚ Î¡ÏŒÎ»Î¿Ï‚ (Ï€ÏÎ¿Î±Î¹ÏÎµÏ„Î¹ÎºÎ¬)\", interactive=True)\n",
        "\n",
        "    with gr.Row():\n",
        "        resume = gr.File(label=\"ğŸ“„ Î’Î¹Î¿Î³ÏÎ±Ï†Î¹ÎºÏŒ (PDF)\", file_types=[\".pdf\"])\n",
        "\n",
        "    with gr.Row():\n",
        "        mode_dropdown = gr.Dropdown(\n",
        "            [\"default\", \"interview\", \"personalized\"],\n",
        "            label=\"Î›ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¯Î±\",\n",
        "            value=\"default\"\n",
        "        )\n",
        "\n",
        "    with gr.Row():\n",
        "        learning_style_input = gr.Dropdown(\n",
        "            choices=[\"visual\", \"auditory\", \"hands-on\"],\n",
        "            label=\"ğŸ“š Î£Ï„Ï…Î» ÎœÎ¬Î¸Î·ÏƒÎ·Ï‚\",\n",
        "            value=default_learning_style,\n",
        "            visible=False\n",
        "        )\n",
        "\n",
        "        career_goals_input = gr.Textbox(\n",
        "            label=\"ğŸ¯ Î£Ï„ÏŒÏ‡Î¿Î¹ ÎšÎ±ÏÎ¹Î­ÏÎ±Ï‚\",\n",
        "            value=default_career_goals,\n",
        "            visible=False\n",
        "        )\n",
        "\n",
        "    mode_dropdown.change(\n",
        "        toggle_personalization_fields,\n",
        "        inputs=[mode_dropdown],\n",
        "        outputs=[learning_style_input, career_goals_input]\n",
        "    )\n",
        "\n",
        "    state = gr.State()\n",
        "\n",
        "    with gr.Row():\n",
        "        submit_btn = gr.Button(\"ğŸš€ Submit\", scale=1)\n",
        "\n",
        "    with gr.Row():\n",
        "        clear_btn = gr.Button(\"ğŸ§¹ Clear\", scale=1)\n",
        "\n",
        "    submit_btn.click(\n",
        "    fn=full_pipeline,\n",
        "          inputs=[\n",
        "              profile, role, resume, state,\n",
        "              mode_dropdown,\n",
        "              learning_style_input,\n",
        "              career_goals_input\n",
        "          ],\n",
        "          outputs=[output_md, state]\n",
        "      )\n",
        "\n",
        "    clear_btn.click(\n",
        "        fn=lambda: (\"\", []),\n",
        "        outputs=[output_md, state]\n",
        "    )"
      ],
      "metadata": {
        "id": "Fu_zbPxZGzQT"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Execution"
      ],
      "metadata": {
        "id": "LKWQeEIXY6a4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "n2-2JMdsY0fB",
        "outputId": "1ce84581-e264-42a6-b014-a6032d29e5fb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://4efee5275702f02721.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://4efee5275702f02721.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  ## ğŸ§  Î‘Î½Î¬Î»Ï…ÏƒÎ· Î”ÎµÎ¾Î¹Î¿Ï„Î®Ï„Ï‰Î½\n",
            "  Î— ÎœÎ±Ï„Î¯Î½Î± Î Î±Ï€Î±Î´Î¬ÎºÎ¿Ï… Î±Î½Î±Î´ÎµÎ¹ÎºÎ½ÏÎµÏ„Î±Î¹ Ï‰Ï‚ Î¼Î¯Î± Î¹Î´Î¹Î±Î¯Ï„ÎµÏÎ± Î´Ï…Î½Î±Î¼Î¹ÎºÎ® ÎºÎ±Î¹ Ï€Î¿Î»Î»Î¬ Ï…Ï€Î¿ÏƒÏ‡ÏŒÎ¼ÎµÎ½Î· Ï€ÏÎ¿ÏƒÏ‰Ï€Î¹ÎºÏŒÏ„Î·Ï„Î± Ï„Î·Ï‚ Gen Z, Î¼Îµ ÏƒÎ±Ï†Î® Ï€ÏÎ¿ÏƒÎ±Î½Î±Ï„Î¿Î»Î¹ÏƒÎ¼ÏŒ ÏƒÏ„Î¿Î½ Ï‡ÏÏÎ¿ Ï„Î·Ï‚ Î Î»Î·ÏÎ¿Ï†Î¿ÏÎ¹ÎºÎ®Ï‚ ÎºÎ±Î¹ Ï„Î·Ï‚ Î¤ÎµÏ‡Î½Î¿Î»Î¿Î³Î¯Î±Ï‚. ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ½ÎµÎ¹ Ï†Î­Ï„Î¿Ï‚ Ï„Î¹Ï‚ ÏƒÏ€Î¿Ï…Î´Î­Ï‚ Ï„Î·Ï‚ ÏƒÏ„Î¿ Î¤Î¼Î®Î¼Î± Î Î»Î·ÏÎ¿Ï†Î¿ÏÎ¹ÎºÎ®Ï‚ Ï„Î¿Ï… Î Î±Î½ÎµÏ€Î¹ÏƒÏ„Î·Î¼Î¯Î¿Ï… Î ÎµÎ¹ÏÎ±Î¹ÏÏ‚, Î­Ï‡Î¿Î½Ï„Î±Ï‚ ÎµÏ€Î¹Î´ÎµÎ¯Î¾ÎµÎ¹ Î±ÎºÎ±Î´Î·Î¼Î±ÏŠÎºÎ® Î±ÏÎ¹ÏƒÏ„ÎµÎ¯Î± Î¼Îµ Ï„ÏÎ­Ï‡Î¿Î½ ÎœÎ­ÏƒÎ¿Ï‚ ÎŒÏÎ¿ Î’Î±Î¸Î¼Î¿Î»Î¿Î³Î¯Î±Ï‚ 8.26. Î‘Ï…Ï„Î® Î· Î¹ÏƒÏ‡Ï…ÏÎ® Î±ÎºÎ±Î´Î·Î¼Î±ÏŠÎºÎ® Ï€Î¿ÏÎµÎ¯Î± Ï„Î·Î½ Î­Ï‡ÎµÎ¹ ÎµÏ†Î¿Î´Î¹Î¬ÏƒÎµÎ¹ Î¼Îµ Î¼Î¯Î± ÏƒÏ„Î­ÏÎµÎ· Î²Î¬ÏƒÎ· ÏƒÏ„Î¹Ï‚ Î±ÏÏ‡Î­Ï‚ Ï„Î·Ï‚ ÎµÏ€Î¹ÏƒÏ„Î®Î¼Î·Ï‚ Ï„Ï‰Î½ Ï…Ï€Î¿Î»Î¿Î³Î¹ÏƒÏ„ÏÎ½, ÎµÎ½Î¹ÏƒÏ‡ÏÎ¿Î½Ï„Î±Ï‚ Ï„Î¹Ï‚ Î´ÎµÎ¾Î¹ÏŒÏ„Î·Ï„Î­Ï‚ Ï„Î·Ï‚ ÏƒÏ„Î·Î½ ÎµÏ€Î¯Î»Ï…ÏƒÎ· Ï€ÏÎ¿Î²Î»Î·Î¼Î¬Ï„Ï‰Î½ ÎºÎ±Î¹ Ï„Î·Î½ Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î±Ï„Î¹ÎºÎ® ÎµÏ†Î±ÏÎ¼Î¿Î³Î® Î¸ÎµÏ‰ÏÎ·Ï„Î¹ÎºÏÎ½ Î³Î½ÏÏƒÎµÏ‰Î½.\n",
            "\n",
            "Î£Îµ ÎµÏ€Î¯Ï€ÎµÎ´Î¿ Ï„ÎµÏ‡Î½Î¹ÎºÏÎ½ Î³Î½ÏÏƒÎµÏ‰Î½ ÎºÎ±Î¹ Î´ÎµÎ¾Î¹Î¿Ï„Î®Ï„Ï‰Î½, Î· ÎœÎ±Ï„Î¯Î½Î± Î´Î¹Î±ÎºÏÎ¯Î½ÎµÏ„Î±Î¹ Î³Î¹Î± Ï„Î·Î½ ÎµÎ½Ï„Ï…Ï€Ï‰ÏƒÎ¹Î±ÎºÎ® Ï„Î·Ï‚ Ï€Î¿Î»Ï…Î³Î»Ï‰ÏƒÏƒÎ¯Î± ÏƒÏ„Î¿Î½ Ï€ÏÎ¿Î³ÏÎ±Î¼Î¼Î±Ï„Î¹ÏƒÎ¼ÏŒ. Î•Î½Ï ÎµÎºÏ†ÏÎ¬Î¶ÎµÎ¹ Î¹Î´Î¹Î±Î¯Ï„ÎµÏÎ· Ï€ÏÎ¿Ï„Î¯Î¼Î·ÏƒÎ· Î³Î¹Î± Ï„Î·Î½ Python, Ï„Î¿ ÏÎµÏ€ÎµÏÏ„ÏŒÏÎ¹ÏŒ Ï„Î·Ï‚ Ï€ÎµÏÎ¹Î»Î±Î¼Î²Î¬Î½ÎµÎ¹ Î­Î½Î± ÎµÏ…ÏÏ Ï†Î¬ÏƒÎ¼Î± Î³Î»Ï‰ÏƒÏƒÏÎ½, ÏŒÏ€Ï‰Ï‚ C#, SQL, Java, C/C++, JavaScript ÎºÎ±Î¹ PHP, Î³ÎµÎ³Î¿Î½ÏŒÏ‚ Ï€Î¿Ï… Î±Ï€Î¿Î´ÎµÎ¹ÎºÎ½ÏÎµÎ¹ Ï„Î·Î½ Ï€ÏÎ¿ÏƒÎ±ÏÎ¼Î¿ÏƒÏ„Î¹ÎºÏŒÏ„Î·Ï„Î¬ Ï„Î·Ï‚ ÏƒÎµ Î´Î¹Î±Ï†Î¿ÏÎµÏ„Î¹ÎºÎ¬ Ï€ÎµÏÎ¹Î²Î¬Î»Î»Î¿Î½Ï„Î± Î±Î½Î¬Ï€Ï„Ï…Î¾Î·Ï‚. Î— Ï„ÎµÏ‡Î½Î¿Î³Î½Ï‰ÏƒÎ¯Î± Ï„Î·Ï‚ ÎµÏ€ÎµÎºÏ„ÎµÎ¯Î½ÎµÏ„Î±Î¹ ÎºÎ±Î¹ ÏƒÏ„Î¿Î½ Ï„Î¿Î¼Î­Î± Ï„Î¿Ï… Front-End Development, ÏŒÏ€Î¿Ï… ÎµÎ¯Î½Î±Î¹ Î¹ÎºÎ±Î½Î® Î½Î± Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÎµÎ¯ HTML ÎºÎ±Î¹ CSS, ÏƒÏ…Î¼Ï€Î»Î·ÏÏÎ½Î¿Î½Ï„Î±Ï‚ Ï„Î¹Ï‚ Î³Î½ÏÏƒÎµÎ¹Ï‚ Ï„Î·Ï‚ Î¼Îµ Ï„Î¿ XAML. Î©Ï‚ Ï€ÏÎ¿Ï‚ Ï„Î¹Ï‚ ÎµÏ†Î±ÏÎ¼Î¿ÏƒÎ¼Î­Î½ÎµÏ‚ Î´ÎµÎ¾Î¹ÏŒÏ„Î·Ï„ÎµÏ‚, ÎºÎ±Ï„Î­Ï‡ÎµÎ¹ Î²Î±Î¸Î¹Î¬ ÎºÎ±Ï„Î±Î½ÏŒÎ·ÏƒÎ· Ï„Î¿Ï… Î‘Î½Ï„Î¹ÎºÎµÎ¹Î¼ÎµÎ½Î¿ÏƒÏ„ÏÎ±Ï†Î¿ÏÏ‚ Î ÏÎ¿Î³ÏÎ±Î¼Î¼Î±Ï„Î¹ÏƒÎ¼Î¿Ï (OOP), ÎµÎ½Ï ÎµÎ¯Î½Î±Î¹ ÎµÎ¾Î¿Î¹ÎºÎµÎ¹Ï‰Î¼Î­Î½Î· Î¼Îµ Ï„Î·Î½ Î±Î½Î¬Ï€Ï„Ï…Î¾Î· ÎµÏ†Î±ÏÎ¼Î¿Î³ÏÎ½ Windows Forms Î¼Î­ÏƒÏ‰ Ï„Î¿Ï… .NET Framework ÎºÎ±Î¹ Ï„Î· Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î“ÏÎ±Ï†Î¹ÎºÏÎ½ Î”Î¹ÎµÏ€Î±Ï†ÏÎ½ Î§ÏÎ®ÏƒÏ„Î· (GUI). Î•Ï€Î¹Ï€Î»Î­Î¿Î½, Î´Î¹Î±Ï‡ÎµÎ¹ÏÎ¯Î¶ÎµÏ„Î±Î¹ Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î±Ï„Î¹ÎºÎ¬ ÎµÏÎ³Î±Î»ÎµÎ¯Î± ÏƒÏ…Î½ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ ÎºÎ±Î¹ Î­ÎºÎ´Î¿ÏƒÎ·Ï‚ ÎºÏÎ´Î¹ÎºÎ±, ÏŒÏ€Ï‰Ï‚ Ï„Î± Git ÎºÎ±Î¹ GitHub, ÎºÎ±Î¹ Î­Ï‡ÎµÎ¹ Î³Î½ÏÏƒÎµÎ¹Ï‚ Î¼Î¿Î½Ï„ÎµÎ»Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚ ÏƒÏ…ÏƒÏ„Î·Î¼Î¬Ï„Ï‰Î½ Î¼Î­ÏƒÏ‰ Ï„Î·Ï‚ UML.\n",
            "\n",
            "Î— Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ® Ï„Î·Ï‚ ÎµÎ¼Ï€ÎµÎ¹ÏÎ¯Î±, Ï€Î±ÏÎ¬ Ï„Î¿ Î³ÎµÎ³Î¿Î½ÏŒÏ‚ ÏŒÏ„Î¹ Î²ÏÎ¯ÏƒÎºÎµÏ„Î±Î¹ Î±ÎºÏŒÎ¼Î· ÏƒÏ„Î± ÏƒÏ„Î¬Î´Î¹Î± Ï„Î·Ï‚ Î±Ï€Î¿Ï†Î¿Î¯Ï„Î·ÏƒÎ·Ï‚, ÎµÎ¯Î½Î±Î¹ Î¬ÎºÏÏ‰Ï‚ ÎµÎ½Î´ÎµÎ¹ÎºÏ„Î¹ÎºÎ® Ï„Ï‰Î½ Î·Î³ÎµÏ„Î¹ÎºÏÎ½ ÎºÎ±Î¹ Î¿ÏÎ³Î±Î½Ï‰Ï„Î¹ÎºÏÎ½ Ï„Î·Ï‚ Î¹ÎºÎ±Î½Î¿Ï„Î®Ï„Ï‰Î½. Î£Ï„Î¿Î½ Î¿ÏÎ³Î±Î½Î¹ÏƒÎ¼ÏŒ UniAI, Ï€Î­ÏÎ±ÏƒÎµ Ï€Î¿Î»Ï Î³ÏÎ®Î³Î¿ÏÎ± Î±Ï€ÏŒ Ï„Î· Î¸Î­ÏƒÎ· Ï„Î·Ï‚ IT and Data Associate, ÏŒÏ€Î¿Ï… ÏƒÏ…Î½ÎµÎ¹ÏƒÎ­Ï†ÎµÏÎµ ÏƒÏ„Î¿Î½ ÏƒÏ‡ÎµÎ´Î¹Î±ÏƒÎ¼ÏŒ ÎºÎ±Î¹ Ï„Î·Î½ Î±Î½Î¬Ï€Ï„Ï…Î¾Î· Î¹ÏƒÏ„Î¿ÏƒÎµÎ»Î¯Î´Ï‰Î½, ÏƒÏ„Î¿Î½ ÏÏŒÎ»Î¿ Ï„Î·Ï‚ IT and Data Responsible. Î£Ï„Î· Î½Î­Î± Ï„Î·Ï‚ Î¸Î­ÏƒÎ·, Î·Î³ÎµÎ¯Ï„Î±Î¹ Ï„Î·Ï‚ Î¿Î¼Î¬Î´Î±Ï‚ Î¤ÎµÏ‡Î½Î¿Î»Î¿Î³Î¯Î±Ï‚ ÎºÎ±Î¹ Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½, ÎµÏ€Î¹Î²Î»Î­Ï€Î¿Î½Ï„Î±Ï‚ Ï„Î·Î½ Î±Î½Î¬Ï€Ï„Ï…Î¾Î· ÎºÎ±Î¹ ÏƒÏ…Î½Ï„Î®ÏÎ·ÏƒÎ· Î¹ÏƒÏ„Î¿ÏƒÎµÎ»Î¯Î´Ï‰Î½, Ï„Î·Î½ Î±Î½Î¬Î»Ï…ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ ÎºÎ±Î¹ Ï„Î·Î½ Ï„ÎµÏ‡Î½Î¹ÎºÎ® Ï…Ï€Î¿Î´Î¿Î¼Î®. ÎŸ ÏÏŒÎ»Î¿Ï‚ Ï„Î·Ï‚ Ï€ÎµÏÎ¹Î»Î±Î¼Î²Î¬Î½ÎµÎ¹ Ï„Î·Î½ ÎµÎ½ÎµÏÎ³ÏŒ ÏƒÏ…Î¼Î¼ÎµÏ„Î¿Ï‡Î® ÏƒÎµ ÏƒÏ…Î½Ï„Î¿Î½Î¹ÏƒÎ¼ÏŒ Ï„ÎµÏ‡Î½Î¿Î»Î¿Î³Î¹ÎºÏÎ½ Î­ÏÎ³Ï‰Î½ ÎºÎ±Î¹, Î±Î¾Î¹Î¿ÏƒÎ·Î¼ÎµÎ¯Ï‰Ï„Î±, Ï„Î·Î½ ÎµÎ¼Ï€Î»Î¿ÎºÎ® ÏƒÎµ Î´Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¯ÎµÏ‚ Î‘Î½Î¸ÏÏÏ€Î¹Î½Î¿Ï… Î”Ï…Î½Î±Î¼Î¹ÎºÎ¿Ï, ÏƒÏ…Î¼Ï€ÎµÏÎ¹Î»Î±Î¼Î²Î±Î½Î¿Î¼Î­Î½Î·Ï‚ Ï„Î·Ï‚ Ï€ÏÏŒÏƒÎ»Î·ÏˆÎ·Ï‚ Î½Î­Ï‰Î½ Î¼ÎµÎ»ÏÎ½, Î³ÎµÎ³Î¿Î½ÏŒÏ‚ Ï€Î¿Ï… Ï…Ï€Î¿Î³ÏÎ±Î¼Î¼Î¯Î¶ÎµÎ¹ Ï„Î¹Ï‚ Î´Î¹Î¿Î¹ÎºÎ·Ï„Î¹ÎºÎ­Ï‚ Ï„Î·Ï‚ Î´Ï…Î½Î±Ï„ÏŒÏ„Î·Ï„ÎµÏ‚.\n",
            "\n",
            "Î Î±ÏÎ¬Î»Î»Î·Î»Î± Î¼Îµ Ï„Î¹Ï‚ ÏƒÏ€Î¿Ï…Î´Î­Ï‚ ÎºÎ±Î¹ Ï„Î·Î½ ÎµÏÎ³Î±ÏƒÎ¹Î±ÎºÎ® Ï„Î·Ï‚ ÎµÎ¼Ï€ÎµÎ¹ÏÎ¯Î±, Î· ÎœÎ±Ï„Î¯Î½Î± ÎµÏ€Î¹Î´ÎµÎ¹ÎºÎ½ÏÎµÎ¹ Î­Î½Ï„Î¿Î½Î· ÎºÎ¿Î¹Î½Ï‰Î½Î¹ÎºÎ® ÏƒÏ…Î½ÎµÎ¯Î´Î·ÏƒÎ· ÎºÎ±Î¹ ÎµÎ¸ÎµÎ»Î¿Î½Ï„Î¹ÎºÏŒ Ï€Î½ÎµÏÎ¼Î±. Î— ÏƒÏ…Î¼Î¼ÎµÏ„Î¿Ï‡Î® Ï„Î·Ï‚ Ï‰Ï‚ ÎµÎ¸ÎµÎ»ÏŒÎ½Ï„ÏÎ¹Î± ÏƒÏ„Î¿ Makeathon UniAI, Î­Î½Î± hackathon ÎµÏƒÏ„Î¹Î±ÏƒÎ¼Î­Î½Î¿ ÏƒÏ„Î·Î½ Î¤ÎµÏ‡Î½Î·Ï„Î® ÎÎ¿Î·Î¼Î¿ÏƒÏÎ½Î·, Ï„Î·Ï‚ ÎµÏ€Î­Ï„ÏÎµÏˆÎµ Î½Î± ÏƒÏ…Î½Î´Ï…Î¬ÏƒÎµÎ¹ Ï„Î·Î½ Î¿ÏÎ³Î±Î½Ï‰Ï„Î¹ÎºÎ® Ï„Î·Ï‚ Î¹ÎºÎ±Î½ÏŒÏ„Î·Ï„Î± Î¼Îµ Ï„Î·Î½ Ï„ÎµÏ‡Î½Î¹ÎºÎ® Ï€ÏÎ¿ÏƒÏ†Î¿ÏÎ¬, ÎºÎ±Î¸ÏÏ‚ Î±ÏƒÏ‡Î¿Î»Î®Î¸Î·ÎºÎµ Î¼Îµ Ï„Î· Î´Î¹Î¿ÏÎ³Î¬Î½Ï‰ÏƒÎ·, Ï„Î·Î½ ÎºÎ±Î¸Î¿Î´Î®Î³Î·ÏƒÎ· Ï„Ï‰Î½ Î´Î¹Î±Î³Ï‰Î½Î¹Î¶Î¿Î¼Î­Î½Ï‰Î½ ÎºÎ±Î¹ Ï„Î¿Î½ ÏƒÏ‡ÎµÎ´Î¹Î±ÏƒÎ¼ÏŒ ÎºÎ±Î¹ Ï„Î·Î½ Î±Î½Î¬Ï€Ï„Ï…Î¾Î· Ï„Î·Ï‚ Î¹ÏƒÏ„Î¿ÏƒÎµÎ»Î¯Î´Î±Ï‚ Ï„Î¿Ï… Î³ÎµÎ³Î¿Î½ÏŒÏ„Î¿Ï‚. Î‘Î½Ï„Î¯ÏƒÏ„Î¿Î¹Ï‡Î±, Î· ÎµÎ½ÎµÏÎ³ÏŒÏ‚ ÏƒÏ…Î½ÎµÎ¹ÏƒÏ†Î¿ÏÎ¬ Ï„Î·Ï‚ ÏƒÏ„Î·Î½ ÎµÏ€Î¹Ï„Ï…Ï‡Î·Î¼Î­Î½Î· ÎµÎºÏ„Î­Î»ÎµÏƒÎ· Ï„Î¿Ï… TEDxUniversityofPiraeus Î±Î½Î±Î´ÎµÎ¹ÎºÎ½ÏÎµÎ¹ Ï„Î·Î½ Î¹ÎºÎ±Î½ÏŒÏ„Î·Ï„Î¬ Ï„Î·Ï‚ Î½Î± Ï€ÏÎ¿Ï‰Î¸ÎµÎ¯ Ï„Î·Î½ Î¹ÏƒÏ‡Ï…ÏÎ® ÏƒÏ…Î½ÎµÏÎ³Î±ÏƒÎ¯Î± ÎºÎ±Î¹ Ï„Î·Î½ Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î±Ï„Î¹ÎºÎ® ÎµÏ€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î¯Î± ÎµÎ½Ï„ÏŒÏ‚ Î¼ÎµÎ³Î¬Î»Ï‰Î½ Î¿Î¼Î¬Î´Ï‰Î½.\n",
            "\n",
            "ÎŒÏƒÎ¿Î½ Î±Ï†Î¿ÏÎ¬ Ï„Î¹Ï‚ Î®Ï€Î¹ÎµÏ‚ Î´ÎµÎ¾Î¹ÏŒÏ„Î·Ï„ÎµÏ‚, Î· ÎœÎ±Ï„Î¯Î½Î± Ï†Î­ÏÎµÎ¹ Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬ Î±Ï€Î±ÏÎ±Î¯Ï„Î·Ï„Î± Î³Î¹Î± Ï„Î· ÏƒÏÎ³Ï‡ÏÎ¿Î½Î· Î±Î³Î¿ÏÎ¬ ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚: Î´Î¹Î±Î¸Î­Ï„ÎµÎ¹ Î±Î½Î±Î»Ï…Ï„Î¹ÎºÎ® ÏƒÎºÎ­ÏˆÎ·, ÎµÎ¯Î½Î±Î¹ Ï€ÏÎ¿ÏƒÎ±ÏÎ¼Î¿ÏƒÏ„Î¹ÎºÎ®, Î­Ï‡ÎµÎ¹ Î¹ÏƒÏ‡Ï…ÏÎ® Î¹ÎºÎ±Î½ÏŒÏ„Î·Ï„Î± ÎµÏ€Î¯Î»Ï…ÏƒÎ·Ï‚ Ï€ÏÎ¿Î²Î»Î·Î¼Î¬Ï„Ï‰Î½ ÎºÎ±Î¹ Î´Î¹Î±Ï€ÏÎ­Ï€ÎµÎ¹ ÏƒÏ„Î·Î½ Î¿Î¼Î±Î´Î¹ÎºÎ® ÎµÏÎ³Î±ÏƒÎ¯Î± ÎºÎ±Î¹ Ï„Î·Î½ Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î±Ï„Î¹ÎºÎ® ÎµÏ€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î¯Î±. Î•ÎºÏ„ÏŒÏ‚ Ï„Î¿Ï… Ï„ÎµÏ‡Î½Î¿Î»Î¿Î³Î¹ÎºÎ¿Ï Ï€ÎµÎ´Î¯Î¿Ï…, Ï„Î± ÎµÎ½Î´Î¹Î±Ï†Î­ÏÎ¿Î½Ï„Î¬ Ï„Î·Ï‚ ÎµÎ¯Î½Î±Î¹ ÎµÏ…ÏÎµÎ¯Î± ÎºÎ±Î¹ ÎºÎ±Î»Î»Î¹Ï„ÎµÏ‡Î½Î¹ÎºÎ¬: Ï€Î­ÏÎ± Î±Ï€ÏŒ Ï„Î·Î½ Î±Î³Î¬Ï€Î· Ï„Î·Ï‚ Î³Î¹Î± Ï„Î¿ coding, ÎµÎºÎ´Î·Î»ÏÎ½ÎµÎ¹ Ï€Î¬Î¸Î¿Ï‚ Î³Î¹Î± Ï„Î¹Ï‚ ÎšÎ±Î»Î­Ï‚ Î¤Î­Ï‡Î½ÎµÏ‚, ÏŒÏ€Î¿Ï… Î¼Î¬Î»Î¹ÏƒÏ„Î± Î´ÏÎ±ÏƒÏ„Î·ÏÎ¹Î¿Ï€Î¿Î¹ÎµÎ¯Ï„Î±Î¹ Ï‰Ï‚ ÎµÏ€Î¹Î¼ÎµÎ»Î®Ï„ÏÎ¹Î± Î¼Î­ÏƒÏ‰ Ï„Î¿Ï… Î»Î¿Î³Î±ÏÎ¹Î±ÏƒÎ¼Î¿Ï @redmattina. Î¤Î­Î»Î¿Ï‚, Î· Î´Î­ÏƒÎ¼ÎµÏ…ÏƒÎ® Ï„Î·Ï‚ ÏƒÏ„Î· ÏƒÏ…Î½ÎµÏ‡Î® Ï€ÏÎ¿ÏƒÏ‰Ï€Î¹ÎºÎ® Î±Î½Î¬Ï€Ï„Ï…Î¾Î· ÎµÎ¯Î½Î±Î¹ ÎµÎ¼Ï†Î±Î½Î®Ï‚ Î¼Î­ÏƒÎ± Î±Ï€ÏŒ Ï„Î·Î½ Î±Î½Î¬Î³Î½Ï‰ÏƒÎ· Î²Î¹Î²Î»Î¯Ï‰Î½ Î»Î¿Î³Î¿Ï„ÎµÏ‡Î½Î¯Î±Ï‚ ÎºÎ±Î¹ Ï„Î·Î½ ÎµÎºÎ¼Î¬Î¸Î·ÏƒÎ· Î³Î»Ï‰ÏƒÏƒÏÎ½, Î¼Îµ Ï„Î± Î™ÏƒÏ€Î±Î½Î¹ÎºÎ¬ Î½Î± Î±Ï€Î¿Ï„ÎµÎ»Î¿ÏÎ½ Ï„Î·Î½ Ï„ÏÎ­Ï‡Î¿Ï…ÏƒÎ± Î³Î»Ï‰ÏƒÏƒÎ¹ÎºÎ® Ï„Î·Ï‚ Ï€ÏÏŒÎºÎ»Î·ÏƒÎ·, ÎµÎ½Ï ÎµÎ¯Î½Î±Î¹ Î®Î´Î· Î´Î¯Î³Î»Ï‰ÏƒÏƒÎ· Î¼Îµ Î¼Î·Ï„ÏÎ¹ÎºÎ® Ï„Î· Î“Î»ÏÏƒÏƒÎ± Î•Î»Î»Î·Î½Î¹ÎºÎ® ÎºÎ±Î¹ Î¬ÏÎ¹ÏƒÏ„Î· Î³Î½ÏÏƒÎ· Ï„Î·Ï‚ Î‘Î³Î³Î»Î¹ÎºÎ®Ï‚ (C2 Level, ECPE).\n",
            "\n",
            "  ## ğŸ’¼ Î ÏÎ¿Ï„ÎµÎ¹Î½ÏŒÎ¼ÎµÎ½Î¿Î¹ Î¡ÏŒÎ»Î¿Î¹\n",
            "  Î— ÎœÎ±Ï„Î¯Î½Î± Î Î±Ï€Î±Î´Î¬ÎºÎ¿Ï… Î´Î¹Î±Î¸Î­Ï„ÎµÎ¹ Î­Î½Î± ÎµÎ¾Î±Î¹ÏÎµÏ„Î¹ÎºÎ¬ Î¹ÏƒÏ‡Ï…ÏÏŒ ÎºÎ±Î¹ Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î·Î¼Î­Î½Î¿ ÏƒÏÎ½Î¿Î»Î¿ Î´ÎµÎ¾Î¹Î¿Ï„Î®Ï„Ï‰Î½ Ï€Î¿Ï… Ï„Î· Î¼ÎµÏ„Î±Ï„ÏÎ­Ï€ÎµÎ¹ Î±Ï€ÏŒ Î¼Î¯Î± Ï€Î¿Î»Î»Î¬ Ï…Ï€Î¿ÏƒÏ‡ÏŒÎ¼ÎµÎ½Î· Î±Ï€ÏŒÏ†Î¿Î¹Ï„Î¿ ÏƒÎµ Î¼Î¯Î± Î¬Î¼ÎµÏƒÎ± Î±Î¾Î¹Î¿Ï€Î¿Î¹Î®ÏƒÎ¹Î¼Î· ÎµÏ€Î±Î³Î³ÎµÎ»Î¼Î±Ï„Î¯Î± Î¼Îµ ÏƒÎ±Ï†ÎµÎ¯Ï‚ Î·Î³ÎµÏ„Î¹ÎºÎ­Ï‚ Î´Ï…Î½Î±Ï„ÏŒÏ„Î·Ï„ÎµÏ‚. ÎŸ ÏƒÏ…Î½Î´Ï…Î±ÏƒÎ¼ÏŒÏ‚ Ï„Î·Ï‚ Î±ÎºÎ±Î´Î·Î¼Î±ÏŠÎºÎ®Ï‚ Î±ÏÎ¹ÏƒÏ„ÎµÎ¯Î±Ï‚ (Î Î»Î·ÏÎ¿Ï†Î¿ÏÎ¹ÎºÎ®, Îœ.ÎŸ. 8.26), Ï„Î·Ï‚ ÎµÎ½Ï„Ï…Ï€Ï‰ÏƒÎ¹Î±ÎºÎ®Ï‚ Ï„ÎµÏ‡Î½Î¹ÎºÎ®Ï‚ Ï€Î¿Î»Ï…Î³Î»Ï‰ÏƒÏƒÎ¯Î±Ï‚ (Python, C#, SQL, Java) ÎºÎ±Î¹ Ï„Î·Ï‚ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ®Ï‚ ÎµÎ¼Ï€ÎµÎ¹ÏÎ¯Î±Ï‚ ÏƒÎµ ÏƒÏ…Î½Ï„Î¿Î½Î¹ÏƒÎ¼ÏŒ Î¿Î¼Î¬Î´Î±Ï‚ (UniAI) Ï„Î·Î½ ÎºÎ±Î¸Î¹ÏƒÏ„Î¬ Î¹Î´Î±Î½Î¹ÎºÎ® Î³Î¹Î± ÏÏŒÎ»Î¿Ï…Ï‚ Ï€Î¿Ï… Î±Ï€Î±Î¹Ï„Î¿ÏÎ½ Ï„ÎµÏ‡Î½Î¹ÎºÎ® ÎµÎºÏ„Î­Î»ÎµÏƒÎ· ÎºÎ±Î¹, Ï„Î±Ï…Ï„ÏŒÏ‡ÏÎ¿Î½Î±, Î´Î¹Î¿Î¹ÎºÎ·Ï„Î¹ÎºÎ® ÎµÏ€Î¿Ï€Ï„ÎµÎ¯Î±.\n",
            "\n",
            "ÎœÎµ Î²Î¬ÏƒÎ· Ï„Î¿ Ï€ÏÎ¿Ï†Î¯Î» Ï„Î·Ï‚, Ï€ÏÎ¿Ï„ÎµÎ¯Î½Î¿Î½Ï„Î±Î¹ Î¿Î¹ Î±ÎºÏŒÎ»Î¿Ï…Î¸Î¿Î¹ Î´ÏÎ¿ (2) ÎµÏ€Î±Î³Î³ÎµÎ»Î¼Î±Ï„Î¹ÎºÎ¿Î¯ ÏÏŒÎ»Î¿Î¹, Î¿Î¹ Î¿Ï€Î¿Î¯Î¿Î¹ Î±Î¾Î¹Î¿Ï€Î¿Î¹Î¿ÏÎ½ ÏƒÏ„Î¿ Î¼Î­Î³Î¹ÏƒÏ„Î¿ Ï„Î¿ Ï†Î¬ÏƒÎ¼Î± Ï„Ï‰Î½ Î´ÎµÎ¾Î¹Î¿Ï„Î®Ï„Ï‰Î½ Ï„Î·Ï‚.\n",
            "\n",
            "---\n",
            "\n",
            "## Î ÏÎ¿Ï„ÎµÎ¹Î½ÏŒÎ¼ÎµÎ½Î¿Î¹ Î•Ï€Î±Î³Î³ÎµÎ»Î¼Î±Ï„Î¹ÎºÎ¿Î¯ Î¡ÏŒÎ»Î¿Î¹ ÎºÎ±Î¹ Î‘Î½Î¬Î»Ï…ÏƒÎ·\n",
            "\n",
            "### Î¡ÏŒÎ»Î¿Ï‚ 1: Î Î¿Î»Ï…Î´Î¹Î¬ÏƒÏ„Î±Ï„Î¿Ï‚ Î ÏÎ¿Î³ÏÎ±Î¼Î¼Î±Ï„Î¹ÏƒÏ„Î®Ï‚ / Full-Stack Developer (ÎœÎµ Î•ÏƒÏ„Î¯Î±ÏƒÎ· ÏƒÎµ .NET/Python)\n",
            "\n",
            "Î‘Ï…Ï„ÏŒÏ‚ Î¿ ÏÏŒÎ»Î¿Ï‚ ÎµÏ€Î¹ÎºÎµÎ½Ï„ÏÏÎ½ÎµÏ„Î±Î¹ ÏƒÏ„Î·Î½ Î±Î¾Î¹Î¿Ï€Î¿Î¯Î·ÏƒÎ· Ï„Î·Ï‚ ÎµÎ½Ï„Ï…Ï€Ï‰ÏƒÎ¹Î±ÎºÎ®Ï‚ Ï„ÎµÏ‡Î½Î¹ÎºÎ®Ï‚ Ï„Î·Ï‚ Î³ÎºÎ¬Î¼Î±Ï‚, ÎµÏ€Î¹Ï„ÏÎ­Ï€Î¿Î½Ï„Î¬Ï‚ Ï„Î·Ï‚ Î½Î± ÏƒÏ…Î½ÎµÎ¹ÏƒÏ†Î­ÏÎµÎ¹ ÏƒÎµ Î´Î¹Î¬Ï†Î¿ÏÎ± ÏƒÏ„Î¬Î´Î¹Î± Ï„Î·Ï‚ Î±Î½Î¬Ï€Ï„Ï…Î¾Î·Ï‚ Î»Î¿Î³Î¹ÏƒÎ¼Î¹ÎºÎ¿Ï, Î±Ï€ÏŒ Ï„Î· Î²Î¬ÏƒÎ· Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ (SQL) Î­Ï‰Ï‚ Ï„Î· Î³ÏÎ±Ï†Î¹ÎºÎ® Î´Î¹ÎµÏ€Î±Ï†Î® (Front-End/GUI).\n",
            "\n",
            "#### Î“Î¹Î±Ï„Î¯ Î¤Î±Î¹ÏÎ¹Î¬Î¶ÎµÎ¹ ÏƒÏ„Î· ÎœÎ±Ï„Î¯Î½Î±:\n",
            "\n",
            "1.  **Î¤ÎµÏ‡Î½Î¹ÎºÎ® Î Î¿Î»Ï…Î³Î»Ï‰ÏƒÏƒÎ¯Î± ÎºÎ±Î¹ Î ÏÎ¿ÏƒÎ±ÏÎ¼Î¿ÏƒÏ„Î¹ÎºÏŒÏ„Î·Ï„Î±:** Î— ÎœÎ±Ï„Î¯Î½Î± ÎºÎ±Ï„Î­Ï‡ÎµÎ¹ Î³Î½ÏÏƒÎµÎ¹Ï‚ ÏƒÎµ Î­Î½Î± ÎµÏ…ÏÏ Ï†Î¬ÏƒÎ¼Î± Î³Î»Ï‰ÏƒÏƒÏÎ½ (Python, C#, Java, JavaScript), ÎµÏ€Î¹Ï„ÏÎ­Ï€Î¿Î½Ï„Î¬Ï‚ Ï„Î·Ï‚ Î½Î± ÎµÎ½ÏƒÏ‰Î¼Î±Ï„Ï‰Î¸ÎµÎ¯ Î¬Î¼ÎµÏƒÎ± ÏƒÎµ Î¿Ï€Î¿Î¹Î¿Î´Î®Ï€Î¿Ï„Îµ Ï„ÎµÏ‡Î½Î¿Î»Î¿Î³Î¹ÎºÏŒ stack. Î— Ï€ÏÎ¿Ï„Î¯Î¼Î·ÏƒÎ® Ï„Î·Ï‚ ÏƒÏ„Î·Î½ Python ÎºÎ±Î¹ Î· Î³Î½ÏÏƒÎ· C#/.NET (Windows Forms, XAML) Ï…Ï€Î¿Î´Î·Î»ÏÎ½Î¿Ï…Î½ Î¹ÎºÎ±Î½ÏŒÏ„Î·Ï„Î± ÏƒÏ„Î·Î½ Î±Î½Î¬Ï€Ï„Ï…Î¾Î· Ï„ÏŒÏƒÎ¿ Î¹ÏƒÏ‡Ï…ÏÏÎ½ back-end ÏƒÏ…ÏƒÏ„Î·Î¼Î¬Ï„Ï‰Î½ ÏŒÏƒÎ¿ ÎºÎ±Î¹ desktop/web ÎµÏ†Î±ÏÎ¼Î¿Î³ÏÎ½.\n",
            "2.  **Î Î»Î®ÏÎ·Ï‚ ÎšÎ±Ï„Î±Î½ÏŒÎ·ÏƒÎ· Î‘Î½Î¬Ï€Ï„Ï…Î¾Î·Ï‚:** Î— Î³Î½ÏÏƒÎ· Ï„Î·Ï‚ ÏƒÏ„Î¿Î½ Î‘Î½Ï„Î¹ÎºÎµÎ¹Î¼ÎµÎ½Î¿ÏƒÏ„ÏÎ±Ï†Î® Î ÏÎ¿Î³ÏÎ±Î¼Î¼Î±Ï„Î¹ÏƒÎ¼ÏŒ (OOP), Ï„Î·Î½ Î±Î½Î¬Ï€Ï„Ï…Î¾Î· GUI ÎºÎ±Î¹ Ï„Î· Ï‡ÏÎ®ÏƒÎ· HTML/CSS Ï„Î·Ï‚ Î´Î¯Î½ÎµÎ¹ Ï„Î· Î´Ï…Î½Î±Ï„ÏŒÏ„Î·Ï„Î± Î½Î± Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î®ÏƒÎµÎ¹ Ï‰Ï‚ Î¿Î»Î¿ÎºÎ»Î·ÏÏ‰Î¼Î­Î½Î¿Ï‚ developer, ÎºÎ±Ï„Î±Î½Î¿ÏÎ½Ï„Î±Ï‚ Ï„Î¹Ï‚ Î±Î»Î»Î·Î»ÎµÏ€Î¹Î´ÏÎ¬ÏƒÎµÎ¹Ï‚ Î¼ÎµÏ„Î±Î¾Ï Front-End ÎºÎ±Î¹ Back-End.\n",
            "3.  **Î•ÏÎ³Î±Î»ÎµÎ¯Î± ÎºÎ±Î¹ ÎŸÏÎ³Î¬Î½Ï‰ÏƒÎ· ÎšÏÎ´Î¹ÎºÎ±:** Î— Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î±Ï„Î¹ÎºÎ® Ï‡ÏÎ®ÏƒÎ· Git/GitHub ÎºÎ±Î¹ Î· Î³Î½ÏÏƒÎ· UML ÎµÎ¾Î±ÏƒÏ†Î±Î»Î¯Î¶Î¿Ï…Î½ ÏŒÏ„Î¹ Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± ÎµÏÎ³Î±ÏƒÏ„ÎµÎ¯ ÏƒÏ…Î»Î»Î¿Î³Î¹ÎºÎ¬, Î½Î± Î´Î¹Î±Ï‡ÎµÎ¹ÏÎ¯Î¶ÎµÏ„Î±Î¹ ÎµÎºÎ´ÏŒÏƒÎµÎ¹Ï‚ ÎºÏÎ´Î¹ÎºÎ± ÎºÎ±Î¹ Î½Î± ÏƒÏ…Î¼Î¼ÎµÏ„Î­Ï‡ÎµÎ¹ ÏƒÎµ Î´Î¹Î±Î´Î¹ÎºÎ±ÏƒÎ¯ÎµÏ‚ Î¼Î¿Î½Ï„ÎµÎ»Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚ ÏƒÏ…ÏƒÏ„Î·Î¼Î¬Ï„Ï‰Î½, Ï‡Î±ÏÎ±ÎºÏ„Î·ÏÎ¹ÏƒÏ„Î¹ÎºÎ¬ Î±Ï€Î±ÏÎ±Î¯Ï„Î·Ï„Î± Î³Î¹Î± Ï„Î·Î½ Î±Î½Î¬Ï€Ï„Ï…Î¾Î· Î¼ÎµÎ³Î¬Î»Ï‰Î½ Î­ÏÎ³Ï‰Î½.\n",
            "\n",
            "#### Î‘Ï€Î±ÏÎ±Î¯Ï„Î·Ï„ÎµÏ‚ Î”ÎµÎ¾Î¹ÏŒÏ„Î·Ï„ÎµÏ‚ Î³Î¹Î± Ï„Î¿Î½ Î¡ÏŒÎ»Î¿:\n",
            "\n",
            "*   **Î’Î±Î¸Î¹Î¬ Î³Î½ÏÏƒÎ· Frameworks:** ÎœÎµÏ„Î¬Î²Î±ÏƒÎ· Î±Ï€ÏŒ Ï„Î· Î³Î½ÏÏƒÎ· Î³Î»Ï‰ÏƒÏƒÏÎ½ ÏƒÏ„Î·Î½ ÎµÎ¾ÎµÎ¹Î´Î¯ÎºÎµÏ…ÏƒÎ· ÏƒÎµ ÏƒÏÎ³Ï‡ÏÎ¿Î½Î± frameworks (Ï€.Ï‡., Python/Django Î® Flask, C#/.NET Core, JavaScript/React Î® Vue).\n",
            "*   **Database Expertise:** Î•Î¾ÎµÎ¹Î´Î¯ÎºÎµÏ…ÏƒÎ· Ï€Î­ÏÎ±Î½ Ï„Î·Ï‚ Î²Î±ÏƒÎ¹ÎºÎ®Ï‚ SQL, ÏƒÎµ Î´Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· Î²Î¬ÏƒÎµÏ‰Î½ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ (Ï€.Ï‡., PostgreSQL, MongoDB) ÎºÎ±Î¹ Î²ÎµÎ»Ï„Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· queries.\n",
            "*   **Cloud Fundamentals:** Î’Î±ÏƒÎ¹ÎºÎ® ÎµÎ¾Î¿Î¹ÎºÎµÎ¯Ï‰ÏƒÎ· Î¼Îµ Ï…Ï€Î·ÏÎµÏƒÎ¯ÎµÏ‚ cloud (Ï€.Ï‡., AWS, Azure Î® GCP) Î³Î¹Î± Ï„Î· Ï†Î¹Î»Î¿Î¾ÎµÎ½Î¯Î± ÎºÎ±Î¹ Ï„Î·Î½ ÎºÎ»Î¹Î¼Î¬ÎºÏ‰ÏƒÎ· ÎµÏ†Î±ÏÎ¼Î¿Î³ÏÎ½.\n",
            "\n",
            "---\n",
            "\n",
            "### Î¡ÏŒÎ»Î¿Ï‚ 2: Junior Technical Lead / Î£Ï…Î½Ï„Î¿Î½Î¯ÏƒÏ„ÏÎ¹Î± Î¤ÎµÏ‡Î½Î¿Î»Î¿Î³Î¹ÎºÏÎ½ ÎˆÏÎ³Ï‰Î½ (Tech Coordinator)\n",
            "\n",
            "Î‘Ï…Ï„ÏŒÏ‚ Î¿ ÏÏŒÎ»Î¿Ï‚ ÏƒÏ…Î½Î´Ï…Î¬Î¶ÎµÎ¹ Ï„Î·Î½ Î¹ÏƒÏ‡Ï…ÏÎ® Ï„ÎµÏ‡Î½Î¹ÎºÎ® Î²Î¬ÏƒÎ· Ï„Î·Ï‚ ÎœÎ±Ï„Î¯Î½Î±Ï‚ Î¼Îµ Ï„Î¹Ï‚ Î®Î´Î· Î±Ï€Î¿Î´ÎµÎ´ÎµÎ¹Î³Î¼Î­Î½ÎµÏ‚ Î·Î³ÎµÏ„Î¹ÎºÎ­Ï‚, Î¿ÏÎ³Î±Î½Ï‰Ï„Î¹ÎºÎ­Ï‚ ÎºÎ±Î¹ Î´Î¹Î¿Î¹ÎºÎ·Ï„Î¹ÎºÎ­Ï‚ Ï„Î·Ï‚ Î´ÎµÎ¾Î¹ÏŒÏ„Î·Ï„ÎµÏ‚ Ï€Î¿Ï… Î±Ï€Î­ÎºÏ„Î·ÏƒÎµ ÏƒÏ„Î¿Î½ ÏÏŒÎ»Î¿ Ï„Î·Ï‚ IT and Data Responsible ÏƒÏ„Î¿ UniAI.\n",
            "\n",
            "#### Î“Î¹Î±Ï„Î¯ Î¤Î±Î¹ÏÎ¹Î¬Î¶ÎµÎ¹ ÏƒÏ„Î· ÎœÎ±Ï„Î¯Î½Î±:\n",
            "\n",
            "1.  **Î‘Ï€Î¿Î´ÎµÎ´ÎµÎ¹Î³Î¼Î­Î½Î· Î—Î³ÎµÏƒÎ¯Î± ÎºÎ±Î¹ Î•Ï€Î¿Ï€Ï„ÎµÎ¯Î±:** Î£Ï„Î¿ UniAI, ÏŒÏ‡Î¹ Î¼ÏŒÎ½Î¿ Î±Î½Î­Î»Î±Î²Îµ Ï„Î·Î½ ÎµÏ…Î¸ÏÎ½Î· Î³Î¹Î± Ï„Î·Î½ Ï„ÎµÏ‡Î½Î¹ÎºÎ® Î¿Î¼Î¬Î´Î± ÎºÎ±Î¹ Ï„Î·Î½ Ï…Ï€Î¿Î´Î¿Î¼Î®, Î±Î»Î»Î¬ ÏƒÏ…Î¼Î¼ÎµÏ„ÎµÎ¯Ï‡Îµ ÎµÎ½ÎµÏÎ³Î¬ ÏƒÏ„Î¿Î½ ÏƒÏ…Î½Ï„Î¿Î½Î¹ÏƒÎ¼ÏŒ Î­ÏÎ³Ï‰Î½ ÎºÎ±Î¹ ÏƒÏ„Î·Î½ Ï€ÏÏŒÏƒÎ»Î·ÏˆÎ· Î½Î­Ï‰Î½ Î¼ÎµÎ»ÏÎ½ (HR), Î´ÎµÎ¯Ï‡Î½Î¿Î½Ï„Î±Ï‚ Î´Î¹Î¿Î¹ÎºÎ·Ï„Î¹ÎºÎ® Ï‰ÏÎ¹Î¼ÏŒÏ„Î·Ï„Î± Ï€Î¿Î»Ï Î½Ï‰ÏÎ¯Ï‚ ÏƒÏ„Î·Î½ ÎºÎ±ÏÎ¹Î­ÏÎ± Ï„Î·Ï‚.\n",
            "2.  **Î™ÏƒÏ‡Ï…ÏÎ® ÎŸÏÎ³Î±Î½Ï‰Ï„Î¹ÎºÎ® Î™ÎºÎ±Î½ÏŒÏ„Î·Ï„Î±:** Î— ÎµÏ€Î¹Ï„Ï…Ï‡Î®Ï‚ ÏƒÏ…Î¼Î¼ÎµÏ„Î¿Ï‡Î® Ï„Î·Ï‚ ÏƒÏ„Î· Î´Î¹Î¿ÏÎ³Î¬Î½Ï‰ÏƒÎ· Ï„Î¿Ï… Makeathon UniAI ÎºÎ±Î¹ Ï„Î¿Ï… TEDxUniversityofPiraeus Î±Ï€Î¿Î´ÎµÎ¹ÎºÎ½ÏÎµÎ¹ Ï„Î·Î½ Î¹ÎºÎ±Î½ÏŒÏ„Î·Ï„Î¬ Ï„Î·Ï‚ Î½Î± Î´Î¹Î±Ï‡ÎµÎ¹ÏÎ¯Î¶ÎµÏ„Î±Î¹ Ï€Î¿Î»ÏÏ€Î»Î¿ÎºÎ± Î­ÏÎ³Î±, Î½Î± ÏƒÏ…Î½Ï„Î¿Î½Î¯Î¶ÎµÎ¹ Î±Î½Î¸ÏÏÏ€Î¿Ï…Ï‚ ÎºÎ±Î¹ Î½Î± Î´Î¹Î±Ï„Î·ÏÎµÎ¯ Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î±Ï„Î¹ÎºÎ® ÎµÏ€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î¯Î± ÎµÎ½Ï„ÏŒÏ‚ Î¼ÎµÎ³Î¬Î»Î·Ï‚ Î¿Î¼Î¬Î´Î±Ï‚.\n",
            "3.  **Î“Î­Ï†Ï…ÏÎ± Î¼ÎµÏ„Î±Î¾Ï Î¤ÎµÏ‡Î½Î¹ÎºÎ¿Ï ÎºÎ±Î¹ Î”Î¹Î¿Î¹ÎºÎ·Ï„Î¹ÎºÎ¿Ï:** Î— ÎœÎ±Ï„Î¯Î½Î± Î´Î¹Î±Î¸Î­Ï„ÎµÎ¹ Ï„Î·Î½ Î±Î½Î±Î»Ï…Ï„Î¹ÎºÎ® ÏƒÎºÎ­ÏˆÎ· (hard skills) Î³Î¹Î± Î½Î± ÎºÎ±Ï„Î±Î½Î¿ÎµÎ¯ Ï„Î¹Ï‚ Ï„ÎµÏ‡Î½Î¹ÎºÎ­Ï‚ Ï€ÏÎ¿ÎºÎ»Î®ÏƒÎµÎ¹Ï‚ ÎºÎ±Î¹, Ï„Î±Ï…Ï„ÏŒÏ‡ÏÎ¿Î½Î±, Ï„Î¹Ï‚ soft skills (ÎµÏ€Î¯Î»Ï…ÏƒÎ· Ï€ÏÎ¿Î²Î»Î·Î¼Î¬Ï„Ï‰Î½, ÎµÏ€Î¹ÎºÎ¿Î¹Î½Ï‰Î½Î¯Î±) Î³Î¹Î± Î½Î± Ï„Î¹Ï‚ Î¼ÎµÏ„Î±Ï†ÏÎ¬Î¶ÎµÎ¹ ÏƒÎµ ÎºÎ±Î¸Î®ÎºÎ¿Î½Ï„Î±, Ï‡ÏÎ¿Î½Î¿Î´Î¹Î±Î³ÏÎ¬Î¼Î¼Î±Ï„Î± ÎºÎ±Î¹ Î±Ï€Î±Î¹Ï„Î®ÏƒÎµÎ¹Ï‚ Î³Î¹Î± Ï„Î·Î½ Î¿Î¼Î¬Î´Î±.\n",
            "\n",
            "#### Î‘Ï€Î±ÏÎ±Î¯Ï„Î·Ï„ÎµÏ‚ Î”ÎµÎ¾Î¹ÏŒÏ„Î·Ï„ÎµÏ‚ Î³Î¹Î± Ï„Î¿Î½ Î¡ÏŒÎ»Î¿:\n",
            "\n",
            "*   **Î”Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ· ÎˆÏÎ³Ï‰Î½ (Agile/Scrum):** Î•Î¾ÎµÎ¹Î´Î¯ÎºÎµÏ…ÏƒÎ· ÏƒÎµ Î¼ÎµÎ¸Î¿Î´Î¿Î»Î¿Î³Î¯ÎµÏ‚ Agile. Î— Î±Ï€ÏŒÎºÏ„Î·ÏƒÎ· Ï€Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚, ÏŒÏ€Ï‰Ï‚ Certified Scrum Master (CSM) Î® Professional Scrum Master (PSM), Î¸Î± Î½Î¿Î¼Î¹Î¼Î¿Ï€Î¿Î¹Î®ÏƒÎµÎ¹ Ï„Î·Î½ Î®Î´Î· Ï…Ï€Î¬ÏÏ‡Î¿Ï…ÏƒÎ± Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ® Ï„Î·Ï‚ ÎµÎ¼Ï€ÎµÎ¹ÏÎ¯Î±.\n",
            "*   **Budgeting ÎºÎ±Î¹ Resource Allocation:** ÎšÎ±Ï„Î±Î½ÏŒÎ·ÏƒÎ· Ï„Ï‰Î½ Î²Î±ÏƒÎ¹ÎºÏÎ½ Î±ÏÏ‡ÏÎ½ Ï„Î·Ï‚ Î´Î¹Î±Ï‡ÎµÎ¯ÏÎ¹ÏƒÎ·Ï‚ Ï€ÏŒÏÏ‰Î½ ÎºÎ±Î¹ Ï„Ï‰Î½ Ï€ÏÎ¿Ï‹Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏÎ½ ÏƒÎµ Ï„ÎµÏ‡Î½Î¿Î»Î¿Î³Î¹ÎºÎ¬ Î­ÏÎ³Î±.\n",
            "*   **Mentorship ÎºÎ±Î¹ Delegating Skills:** Î‘Î½Î¬Ï€Ï„Ï…Î¾Î· Î¹ÎºÎ±Î½ÏŒÏ„Î·Ï„Î±Ï‚ ÎºÎ±Î¸Î¿Î´Î®Î³Î·ÏƒÎ·Ï‚ junior Î¼ÎµÎ»ÏÎ½ ÎºÎ±Î¹ Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î±Ï„Î¹ÎºÎ®Ï‚ Î±Î½Î¬Î¸ÎµÏƒÎ·Ï‚ Ï„ÎµÏ‡Î½Î¹ÎºÏÎ½ ÎµÏÎ³Î±ÏƒÎ¹ÏÎ½, Î´Î¹Î±Ï„Î·ÏÏÎ½Ï„Î±Ï‚ Ï„Î·Î½ ÎµÏ€Î¿Ï€Ï„ÎµÎ¯Î± Ï„Î·Ï‚ Ï€Î¿Î¹ÏŒÏ„Î·Ï„Î±Ï‚ Ï„Î¿Ï… ÎºÏÎ´Î¹ÎºÎ±.\n",
            "\n",
            "---\n",
            "\n",
            "## Î•Ï€ÏŒÎ¼ÎµÎ½Î± Î’Î®Î¼Î±Ï„Î± Î•Ï€Î±Î³Î³ÎµÎ»Î¼Î±Ï„Î¹ÎºÎ®Ï‚ Î ÏÎ¿ÏÎ¸Î·ÏƒÎ·Ï‚ Î³Î¹Î± Ï„Î· ÎœÎ±Ï„Î¯Î½Î±\n",
            "\n",
            "Î“Î¹Î± Î½Î± ÎºÎµÏ†Î±Î»Î±Î¹Î¿Ï€Î¿Î¹Î®ÏƒÎµÎ¹ Ï€Î»Î®ÏÏ‰Ï‚ Ï„Î¹Ï‚ Î´ÎµÎ¾Î¹ÏŒÏ„Î·Ï„Î­Ï‚ Ï„Î·Ï‚ ÎºÎ±Î¹ Î½Î± Ï€ÏÎ¿Ï‡Ï‰ÏÎ®ÏƒÎµÎ¹ ÎµÏ€Î¹Ï„Ï…Ï‡ÏÏ‚ ÏƒÎµ Î­Î½Î±Î½ Î±Ï€ÏŒ Ï„Î¿Ï…Ï‚ Ï€Î±ÏÎ±Ï€Î¬Î½Ï‰ ÏÏŒÎ»Î¿Ï…Ï‚, Î· ÎœÎ±Ï„Î¯Î½Î± Î¸Î± Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± ÎµÏƒÏ„Î¹Î¬ÏƒÎµÎ¹ ÏƒÏ„Î¿Ï…Ï‚ Î±ÎºÏŒÎ»Î¿Ï…Î¸Î¿Ï…Ï‚ Ï„ÏÎµÎ¹Ï‚ Ï„Î¿Î¼ÎµÎ¯Ï‚:\n",
            "\n",
            "### 1. Î•Î¾ÎµÎ¹Î´Î¯ÎºÎµÏ…ÏƒÎ· ÎºÎ±Î¹ ÎšÎ±Î¸Î¿ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î¤ÎµÏ‡Î½Î¿Î»Î¿Î³Î¹ÎºÎ¿Ï Î£Ï„Î¬Îº (Tech Deep Dive)\n",
            "\n",
            "Î•Î½Ï Î· Ï€Î¿Î»Ï…Î³Î»Ï‰ÏƒÏƒÎ¯Î± ÎµÎ¯Î½Î±Î¹ Î­Î½Î± Ï„ÎµÏÎ¬ÏƒÏ„Î¹Î¿ Ï€Î»ÎµÎ¿Î½Î­ÎºÏ„Î·Î¼Î±, Î· Î±Î³Î¿ÏÎ¬ ÎµÏÎ³Î±ÏƒÎ¯Î±Ï‚ Î±Î½Î±Î¶Î·Ï„Î¬ ÏƒÏ…Ï‡Î½Î¬ Î²Î¬Î¸Î¿Ï‚ ÏƒÎµ Î¼Î¯Î± ÏƒÏ…Î³ÎºÎµÎºÏÎ¹Î¼Î­Î½Î· Ï„ÎµÏ‡Î½Î¿Î»Î¿Î³Î¯Î±.\n",
            "\n",
            "*   **Î•Ï€Î¹Î»Î¿Î³Î® Focus:** Î— ÎœÎ±Ï„Î¯Î½Î± Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± ÎµÏ€Î¹Î»Î­Î¾ÎµÎ¹ Î±Î½ Î¸Î­Î»ÎµÎ¹ Î½Î± ÎµÎ¼Î²Î±Î¸ÏÎ½ÎµÎ¹ ÏƒÏ„Î¿ Î¿Î¹ÎºÎ¿ÏƒÏÏƒÏ„Î·Î¼Î± Ï„Î·Ï‚ Python (Ï€.Ï‡., Data Science/ML frameworks, Î´ÎµÎ´Î¿Î¼Î­Î½Î¿Ï… Ï„Î¿Ï… ÏÏŒÎ»Î¿Ï… Ï„Î·Ï‚ ÏƒÏ„Î¿ UniAI) Î® ÏƒÏ„Î¿ Î¿Î¹ÎºÎ¿ÏƒÏÏƒÏ„Î·Î¼Î± .NET (Ï€Î¿Ï… Ï„Î·Ï‚ Ï€Î±ÏÎ­Ï‡ÎµÎ¹ Ï€ÏÏŒÏƒÎ²Î±ÏƒÎ· ÏƒÎµ enterprise development Î¼Î­ÏƒÏ‰ C# ÎºÎ±Î¹ Azure).\n",
            "*   **Î ÏÏŒÏƒÎ¸ÎµÏ„Î± Projects:** Î‘Î½Î¬Ï€Ï„Ï…Î¾Î· ÎµÎ½ÏŒÏ‚ Ï€ÏÎ¿ÏƒÏ‰Ï€Î¹ÎºÎ¿Ï project Ï€Î»Î®ÏÎ¿Ï…Ï‚ ÎºÎ»Î¯Î¼Î±ÎºÎ±Ï‚ (Full-Stack) Ï‡ÏÎ·ÏƒÎ¹Î¼Î¿Ï€Î¿Î¹ÏÎ½Ï„Î±Ï‚ Î­Î½Î± ÏƒÏÎ³Ï‡ÏÎ¿Î½Î¿ stack (Ï€.Ï‡., React/Vue Î³Î¹Î± Front-End, Django/FastAPI Î³Î¹Î± Back-End) Î³Î¹Î± Î½Î± ÎµÏ€Î¹Î´ÎµÎ¯Î¾ÎµÎ¹ Î¹ÎºÎ±Î½ÏŒÏ„Î·Ï„Î± ÏƒÎµ end-to-end ÎµÏ†Î±ÏÎ¼Î¿Î³Î®.\n",
            "\n",
            "### 2. Î‘Ï€ÏŒÎºÏ„Î·ÏƒÎ· Î Î¹ÏƒÏ„Î¿Ï€Î¿Î¹Î®ÏƒÎµÏ‰Î½ ÎºÎ±Î¹ Î¤Ï…Ï€Î¹ÎºÏÎ½ Î ÏÎ¿ÏƒÏŒÎ½Ï„Ï‰Î½ Î”Î¹Î¿Î¯ÎºÎ·ÏƒÎ·Ï‚\n",
            "\n",
            "Î“Î¹Î± Î½Î± Î¼ÎµÏ„Î±Ï„ÏÎ­ÏˆÎµÎ¹ Ï„Î·Î½ Ï€ÏÎ±ÎºÏ„Î¹ÎºÎ® Ï„Î·Ï‚ ÎµÎ¼Ï€ÎµÎ¹ÏÎ¯Î± Î·Î³ÎµÏƒÎ¯Î±Ï‚ ÏƒÎµ ÎµÏ€Î¯ÏƒÎ·Î¼Î¿ Ï€ÏÎ¿ÏƒÏŒÎ½, Î· ÎœÎ±Ï„Î¯Î½Î± Î¸Î± Ï€ÏÎ­Ï€ÎµÎ¹ Î½Î± ÎµÏ€Î¹ÎºÏ…ÏÏÏƒÎµÎ¹ Ï„Î¹Ï‚ Î³Î½ÏÏƒÎµÎ¹Ï‚ Ï„Î·Ï‚.\n",
            "\n",
            "*   **Î Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ· Agile:** Î‘Ï€ÏŒÎºÏ„Î·ÏƒÎ· Ï€Î¹ÏƒÏ„Î¿Ï€Î¿Î¯Î·ÏƒÎ·Ï‚ **Scrum Master (CSM)** Î® **PSM**, ÏÏƒÏ„Îµ Î½Î± Î¼Ï€Î¿ÏÎµÎ¯ Î½Î± Î´Î¹ÎµÎºÎ´Î¹ÎºÎ®ÏƒÎµÎ¹ Î¬Î¼ÎµÏƒÎ± ÏÏŒÎ»Î¿Ï…Ï‚ Ï„ÎµÏ‡Î½Î¹ÎºÎ¿Ï ÏƒÏ…Î½Ï„Î¿Î½Î¹ÏƒÎ¼Î¿Ï (Tech Coordinator/Team Lead), Î±ÎºÏŒÎ¼Î· ÎºÎ±Î¹ ÏƒÎµ junior ÎµÏ€Î¯Ï€ÎµÎ´Î¿.\n",
            "*   **Î•Î½Î¯ÏƒÏ‡Ï…ÏƒÎ· Î”ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½:** Î•Ï†ÏŒÏƒÎ¿Î½ Î¿ Ï€ÏÎ¿Î·Î³Î¿ÏÎ¼ÎµÎ½Î¿Ï‚ ÏÏŒÎ»Î¿Ï‚ Ï„Î·Ï‚ Ï€ÎµÏÎ¹Î»Î¬Î¼Î²Î±Î½Îµ Ï„Î¿ Data, Î¸Î± Î¼Ï€Î¿ÏÎ¿ÏÏƒÎµ Î½Î± ÎµÎ½Î¹ÏƒÏ‡ÏÏƒÎµÎ¹ Ï„Î¹Ï‚ Î´ÎµÎ¾Î¹ÏŒÏ„Î·Ï„Î­Ï‚ Ï„Î·Ï‚ ÏƒÎµ ÎµÏÎ³Î±Î»ÎµÎ¯Î± Î±Î½Î¬Î»Ï…ÏƒÎ·Ï‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½ (Ï€.Ï‡., Power BI, Tableau) Î® ÏƒÎµ Î²Î±ÏƒÎ¹ÎºÎ­Ï‚ Î±ÏÏ‡Î­Ï‚ Cloud (Ï€.Ï‡., **AWS Certified Cloud Practitioner**).\n",
            "\n",
            "### 3. ÎœÎ¬ÏÎºÎµÏ„Î¹Î½Î³Îº Î ÏÎ¿ÏƒÏ‰Ï€Î¹ÎºÎ®Ï‚ Î•Î¹ÎºÏŒÎ½Î±Ï‚ (Personal Branding)\n",
            "\n",
            "Î— ÎœÎ±Ï„Î¯Î½Î± Î­Ï‡ÎµÎ¹ Î­Î½Î± Î¼Î¿Î½Î±Î´Î¹ÎºÏŒ Ï€Î»ÎµÎ¿Î½Î­ÎºÏ„Î·Î¼Î±: Ï„Î¿Î½ ÏƒÏ…Î½Î´Ï…Î±ÏƒÎ¼ÏŒ Ï„Î·Ï‚ Ï„ÎµÏ‡Î½Î¿Î»Î¿Î³Î¯Î±Ï‚ Î¼Îµ Ï„Î¹Ï‚ ÎšÎ±Î»Î­Ï‚ Î¤Î­Ï‡Î½ÎµÏ‚. Î‘Ï…Ï„Î® Î· Î´Î¹Î¬ÏƒÏ„Î±ÏƒÎ· Ï…Ï€Î¿Î´Î·Î»ÏÎ½ÎµÎ¹ Î¹Î´Î¹Î±Î¯Ï„ÎµÏÎ· Ï€ÏÎ¿ÏƒÎ¿Ï‡Î® ÏƒÏ„Î¿ UX/UI ÎºÎ±Î¹ Ï„Î· Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î¹ÎºÏŒÏ„Î·Ï„Î±.\n",
            "\n",
            "*   **Î•Î½Î¿Ï€Î¿Î¯Î·ÏƒÎ· Î ÏÎ¿Ï†Î¯Î»:** ÎÎ± Î±Î½Î±Î´ÎµÎ¯Î¾ÎµÎ¹ ÏƒÏ„Î¿Î½ ÎµÏ€Î±Î³Î³ÎµÎ»Î¼Î±Ï„Î¹ÎºÏŒ Ï„Î·Ï‚ Î»Î¿Î³Î±ÏÎ¹Î±ÏƒÎ¼ÏŒ (Ï€.Ï‡., LinkedIn) Ï„Î· ÏƒÏÎ½Î´ÎµÏƒÎ· Î¼ÎµÏ„Î±Î¾Ï Ï„Î·Ï‚ ÎºÎ±Î»Î»Î¹Ï„ÎµÏ‡Î½Î¹ÎºÎ®Ï‚ Ï„Î·Ï‚ Ï€Î»ÎµÏ…ÏÎ¬Ï‚ (@redmattina) ÎºÎ±Î¹ Ï„Î·Ï‚ Î¹ÎºÎ±Î½ÏŒÏ„Î·Ï„Î¬Ï‚ Ï„Î·Ï‚ Î½Î± Î´Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ Î»ÎµÎ¹Ï„Î¿Ï…ÏÎ³Î¹ÎºÎ¬ ÎºÎ±Î¹ Î±Î¹ÏƒÎ¸Î·Ï„Î¹ÎºÎ¬ ÎµÏ…Ï‡Î¬ÏÎ¹ÏƒÏ„Î± Î“ÏÎ±Ï†Î¹ÎºÎ¬ Î”Î¹ÎµÏ€Î±Ï†ÏÎ½ Î§ÏÎ®ÏƒÏ„Î· (GUI) ÎºÎ±Î¹ Front-End.\n",
            "*   **Î”Î¯ÎºÏ„Ï…Î¿:** ÎÎ± ÏƒÏ…Î½ÎµÏ‡Î¯ÏƒÎµÎ¹ Ï„Î·Î½ ÎµÎ½ÎµÏÎ³ÏŒ ÏƒÏ…Î¼Î¼ÎµÏ„Î¿Ï‡Î® ÏƒÎµ Ï„ÎµÏ‡Î½Î¿Î»Î¿Î³Î¹ÎºÎ­Ï‚ ÎºÎ±Î¹ ÎµÎ¸ÎµÎ»Î¿Î½Ï„Î¹ÎºÎ­Ï‚ Î´ÏÎ¬ÏƒÎµÎ¹Ï‚ (ÏŒÏ€Ï‰Ï‚ Ï„Î¿ TEDx), Î´Î·Î¼Î¹Î¿Ï…ÏÎ³ÏÎ½Ï„Î±Ï‚ Î­Î½Î± Î¹ÏƒÏ‡Ï…ÏÏŒ ÎµÏ€Î±Î³Î³ÎµÎ»Î¼Î±Ï„Î¹ÎºÏŒ Î´Î¯ÎºÏ„Ï…Î¿, Ï„Î¿ Î¿Ï€Î¿Î¯Î¿ ÎµÎ¯Î½Î±Î¹ Î¶Ï‰Ï„Î¹ÎºÎ®Ï‚ ÏƒÎ·Î¼Î±ÏƒÎ¯Î±Ï‚ Î³Î¹Î± ÏÏŒÎ»Î¿Ï…Ï‚ ÏƒÏ…Î½Ï„Î¿Î½Î¹ÏƒÎ¼Î¿Ï ÎºÎ±Î¹ Î·Î³ÎµÏƒÎ¯Î±Ï‚.\n",
            "\n",
            "\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://4efee5275702f02721.gradio.live\n"
          ]
        }
      ]
    }
  ]
}